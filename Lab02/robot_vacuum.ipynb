{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoZaeOrwTwct"
      },
      "source": [
        "# Intelligent Agents: Reflex-Based Agents for the Vacuum-cleaner World\n",
        "\n",
        "Student Name: [Add your name]\n",
        "\n",
        "I have used the following AI tools: [list tools]\n",
        "\n",
        "I understand that my submission needs to be my own work: [your initials]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5t6TXaJTwc0"
      },
      "source": [
        "## Learning Outcomes\n",
        "\n",
        "* Design and build a simulation environment that models sensor inputs, actuator effects, and performance measurement.\n",
        "* Apply core AI concepts by implementing the agent function for a simple and model-based reflex agents that respond to environmental percepts.\n",
        "* Practice how the environment and the agent function interact.\n",
        "* Analyze agent performance through controlled experiments across different environment configurations.\n",
        "* Graduate Students: Develop strategies for handling uncertainty and imperfect information in autonomous agent systems.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undergrads 98 + 5 bonus / Graduate students 110\n",
        "\n",
        "Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "### AI Use\n",
        "\n",
        "Here are some guidelines that will make it easier for you:\n",
        "\n",
        "* __Don't:__ Rely on AI auto completion. You will waste a lot of time trying to figure out how the suggested code relates to what we do in class. Turn off AI code completion (e.g., Copilot) in your IDE.\n",
        "* __Don't:__ Do not submit code/text that you do not understand or have not checked to make sure that it is complete and correct.\n",
        "* __Do:__ Use AI for debugging and letting it explain code and concepts from class.\n",
        "\n",
        "### Using Visual Studio Code\n",
        "\n",
        "If you use VS code then you can use `Export` (click on `...` in the menu bar) to save your notebook as a HTML file. Note that you have to run all blocks before so the HTML file contains your output.\n",
        "\n",
        "### Using Google Colab\n",
        "\n",
        "In Colab you need to save the notebook on GoogleDrive to work with it. For this you need to mount your google dive and change to the correct directory by uncommenting the following lines and running the code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxK0ZFTuTwc3"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "#\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/My Drive/Colab Notebooks/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSnf-SXyTwc7"
      },
      "source": [
        "Once you are done with the assignment and have run all code blocks using `Runtime/Run all`, you can convert the file on your GoogleDrive into HTML be uncommenting the following line and running the block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bodK0U3Twc8"
      },
      "outputs": [],
      "source": [
        "# %jupyter nbconvert --to html Copy\\ of\\ robot_vacuum.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNxW0nyiTwc9"
      },
      "source": [
        "You may have to fix the file location or the file name to match how it looks on your GoogleDrive. You can navigate in Colab to your GoogleDrive using the little folder symbol in the navigation bar to the left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJKd38FTwc-"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this assignment you will implement a simulator environment for an automatic vacuum cleaner robot, a set of different reflex-based agent programs, and perform a comparison study for cleaning a single room. Focus on the __cleaning phase__ which starts when the robot is activated and ends when the last dirty square in the room has been cleaned. Someone else will take care of the agent program needed to navigate back to the charging station after the room is clean.\n",
        "\n",
        "## PEAS description of the cleaning phase\n",
        "\n",
        "__Performance Measure:__ Each action costs 1 energy unit. The performance is measured as the sum of the energy units used to clean the whole room.\n",
        "\n",
        "__Environment:__ A room with $n \\times n$ squares where $n = 5$. Dirt is randomly placed on each square with probability $p = 0.2$. For simplicity, you can assume that the agent knows the size and the layout of the room (i.e., it knows $n$). To start, the agent is placed on a random square.\n",
        "\n",
        "__Actuators:__ The agent can clean the current square (action `suck`) or move to an adjacent square by going `north`, `east`, `south`, or `west`.\n",
        "\n",
        "__Sensors:__ Four bumper sensors, one for north, east, south, and west; a dirt sensor reporting dirt in the current square.  \n",
        "\n",
        "\n",
        "## The agent program for a simple randomized agent\n",
        "\n",
        "The agent program is a function that gets sensor information (the current percepts) as the arguments. The arguments are:\n",
        "\n",
        "* A dictionary with boolean entries for the for bumper sensors `north`, `east`, `west`, `south`. E.g., if the agent is on the north-west corner, `bumpers` will be `{\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}`.\n",
        "* The dirt sensor produces a boolean.\n",
        "\n",
        "The agent returns the chosen action as a string.\n",
        "\n",
        "Here is an example implementation for the agent program of a simple randomized agent:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNoAPGQYTwdA"
      },
      "outputs": [],
      "source": [
        "# make sure numpy is installed\n",
        "%pip install -q numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OGhZMnCTwdC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
        "\n",
        "def simple_randomized_agent(bumpers, dirty):\n",
        "    return np.random.choice(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZR62CRpTwdE",
        "outputId": "21a0835d-49b5-4ae6-cb67-bb816a30e48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.str_('east')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# define percepts (current location is NW corner and it is dirty)\n",
        "bumpers = {\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}\n",
        "dirty = True\n",
        "\n",
        "# call agent program function with percepts and it returns an action\n",
        "simple_randomized_agent(bumpers, dirty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_U8lSLlTwdF"
      },
      "source": [
        "__Note:__ This is not a rational intelligent agent. It ignores its sensors and may bump into a wall repeatedly or not clean a dirty square. You will be asked to implement rational agents below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wA14nnWTwdG"
      },
      "source": [
        "## Simple environment example\n",
        "\n",
        "We implement a simple simulation environment that supplies the agent with its percepts.\n",
        "The simple environment is infinite in size (bumpers are always `False`) and every square is always dirty, even if the agent cleans it. The environment function returns a different performance measure than the one specified in the PEAS description! Since the room is infinite and all squares are constantly dirty, the agent can never clean the whole room. Your implementation needs to implement the **correct performance measure.** The energy budget of the agent is specified as `max_steps`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_wBPN9GTwdH"
      },
      "outputs": [],
      "source": [
        "def simple_environment(agent_function, max_steps, verbose = True):\n",
        "    num_cleaned = 0\n",
        "\n",
        "    for i in range(max_steps):\n",
        "        dirty = True\n",
        "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
        "\n",
        "        action = agent_function(bumpers, dirty)\n",
        "        if (verbose): print(\"step\", i , \"- action:\", action)\n",
        "\n",
        "        if (action == \"suck\"):\n",
        "            num_cleaned = num_cleaned + 1\n",
        "\n",
        "    return num_cleaned\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep7R6hcgTwdI"
      },
      "source": [
        "Do one simulation run with a simple randomized agent that has enough energy for 20 steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObJksdcITwdJ",
        "outputId": "7d61a03c-fda7-470e-e25a-8234cb385871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 - action: north\n",
            "step 1 - action: north\n",
            "step 2 - action: south\n",
            "step 3 - action: east\n",
            "step 4 - action: east\n",
            "step 5 - action: east\n",
            "step 6 - action: suck\n",
            "step 7 - action: east\n",
            "step 8 - action: suck\n",
            "step 9 - action: south\n",
            "step 10 - action: south\n",
            "step 11 - action: east\n",
            "step 12 - action: suck\n",
            "step 13 - action: south\n",
            "step 14 - action: west\n",
            "step 15 - action: suck\n",
            "step 16 - action: north\n",
            "step 17 - action: west\n",
            "step 18 - action: west\n",
            "step 19 - action: north\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "simple_environment(simple_randomized_agent, max_steps = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1M_CxGkTwdJ"
      },
      "source": [
        "# Tasks\n",
        "\n",
        "## General [10 Points]\n",
        "\n",
        "1. Make sure that you use the latest version of this notebook.\n",
        "2. Your implementation can use libraries like math, numpy, scipy, but not libraries that implement intelligent agents or complete search algorithms. Try to keep the code simple! In this course, we want to learn about the algorithms and we often do not need to use object-oriented design.\n",
        "3. You notebook needs to be formatted professionally.\n",
        "    - Add additional markdown blocks for your description, comments in the code, add tables and use mathplotlib to produce charts where appropriate\n",
        "    - Do not show debugging output or include an excessive amount of output.\n",
        "    - Check that your submitted file is readable and contains all figures.\n",
        "4. Document your code. Use comments in the code and add a discussion of how your implementation works and your design choices.\n",
        "\n",
        "\n",
        "## Task 1: Implement a simulation environment [20 Points]\n",
        "\n",
        "The simple environment above is not very realistic. Your environment simulator needs to follow the PEAS description from above. It needs to:\n",
        "\n",
        "* Initialize the environment by storing the state of each square (clean/dirty) and making some dirty. ([Help with random numbers and arrays in Python](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/random_numbers_and_arrays.ipynb))\n",
        "* Keep track of the agent's position.\n",
        "* Call the agent function repeatedly and provide the agent function with the sensor inputs.  \n",
        "* React to the agent's actions. E.g, by removing dirt from a square or moving the agent around unless there is a wall in the way.\n",
        "* Keep track of the performance measure. That is, track the agent's actions until all dirty squares are clean and count the number of actions it takes the agent to complete the task.\n",
        "\n",
        "The easiest implementation for the environment is to hold an 2-dimensional array to represent if squares are clean or dirty and to call the agent function in a loop until all squares are clean or a predefined number of steps have been reached (i.e., the robot runs out of energy).\n",
        "\n",
        "The simulation environment should be a function like the `simple_environment()` and needs to work with the simple randomized agent program from above. **Use the same environment for all your agent implementations in the tasks below.**\n",
        "\n",
        "*Note on debugging:* Debugging is difficult. Make sure your environment prints enough information when you use `verbose = True`. Also, implementing a function that the environment can use to displays the room with dirt and the current position of the robot at every step is very useful.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRyv9taITwdK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Các action có thể\n",
        "ACTIONS = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
        "\n",
        "def vacuum_environment(agent_function, n=5, p=0.2, max_steps=200, verbose=True):\n",
        "    \"\"\"\n",
        "    Môi trường vacuum cleaner mô phỏng theo PEAS.\n",
        "\n",
        "    Parameters:\n",
        "        agent_function : hàm agent (ví dụ simple_randomized_agent)\n",
        "        n : kích thước phòng n x n\n",
        "        p : xác suất ô bẩn ban đầu\n",
        "        max_steps : số bước tối đa (năng lượng)\n",
        "        verbose : nếu True sẽ in trạng thái từng bước\n",
        "\n",
        "    Returns:\n",
        "        steps_taken : số bước agent đã dùng để dọn sạch phòng\n",
        "    \"\"\"\n",
        "    # Khởi tạo môi trường: ma trận dirty (True=dirty, False=clean)\n",
        "    room = np.random.choice([True, False], size=(n,n), p=[p, 1-p])\n",
        "\n",
        "    # Chọn vị trí ban đầu ngẫu nhiên\n",
        "    agent_pos = [random.randint(0, n-1), random.randint(0, n-1)]\n",
        "\n",
        "    steps_taken = 0\n",
        "\n",
        "    while steps_taken < max_steps:\n",
        "        r, c = agent_pos\n",
        "\n",
        "        # Cảm biến dirt sensor\n",
        "        dirty = room[r, c]\n",
        "\n",
        "        # Cảm biến bumper\n",
        "        bumpers = {\n",
        "            \"north\": (r == 0),\n",
        "            \"south\": (r == n-1),\n",
        "            \"west\":  (c == 0),\n",
        "            \"east\":  (c == n-1)\n",
        "        }\n",
        "\n",
        "        # Gọi agent để lấy action\n",
        "        action = agent_function(bumpers, dirty)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Step {steps_taken}: pos=({r},{c}), dirty={dirty}, action={action}\")\n",
        "\n",
        "        # Thực hiện action\n",
        "        if action == \"suck\":\n",
        "            room[r, c] = False  # làm sạch ô hiện tại\n",
        "        elif action == \"north\" and not bumpers[\"north\"]:\n",
        "            agent_pos[0] -= 1\n",
        "        elif action == \"south\" and not bumpers[\"south\"]:\n",
        "            agent_pos[0] += 1\n",
        "        elif action == \"west\" and not bumpers[\"west\"]:\n",
        "            agent_pos[1] -= 1\n",
        "        elif action == \"east\" and not bumpers[\"east\"]:\n",
        "            agent_pos[1] += 1\n",
        "        # Nếu agent chọn đi vào tường, thì agent không di chuyển\n",
        "\n",
        "        steps_taken += 1\n",
        "\n",
        "        # Kiểm tra nếu tất cả ô đều sạch\n",
        "        if not room.any():\n",
        "            if verbose:\n",
        "                print(f\" All squares cleaned in {steps_taken} steps.\")\n",
        "            break\n",
        "\n",
        "    return steps_taken\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PNKqTQOTwdL"
      },
      "source": [
        "Show that your environment works with the simple randomized agent from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4l-WLWYTwdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9f8d09-8e22-4395-a5b6-723aee878e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: pos=(4,4), dirty=False, action=south\n",
            "Step 1: pos=(4,4), dirty=False, action=east\n",
            "Step 2: pos=(4,4), dirty=False, action=east\n",
            "Step 3: pos=(4,4), dirty=False, action=east\n",
            "Step 4: pos=(4,4), dirty=False, action=west\n",
            "Step 5: pos=(4,3), dirty=False, action=east\n",
            "Step 6: pos=(4,4), dirty=False, action=north\n",
            "Step 7: pos=(3,4), dirty=False, action=north\n",
            "Step 8: pos=(2,4), dirty=False, action=west\n",
            "Step 9: pos=(2,3), dirty=False, action=north\n",
            "Step 10: pos=(1,3), dirty=False, action=suck\n",
            "Step 11: pos=(1,3), dirty=False, action=west\n",
            "Step 12: pos=(1,2), dirty=False, action=north\n",
            "Step 13: pos=(0,2), dirty=True, action=suck\n",
            "Step 14: pos=(0,2), dirty=False, action=suck\n",
            "Step 15: pos=(0,2), dirty=False, action=north\n",
            "Step 16: pos=(0,2), dirty=False, action=east\n",
            "Step 17: pos=(0,3), dirty=False, action=south\n",
            "Step 18: pos=(1,3), dirty=False, action=south\n",
            "Step 19: pos=(2,3), dirty=False, action=north\n",
            "Step 20: pos=(1,3), dirty=False, action=north\n",
            "Step 21: pos=(0,3), dirty=False, action=east\n",
            "Step 22: pos=(0,4), dirty=True, action=south\n",
            "Step 23: pos=(1,4), dirty=False, action=west\n",
            "Step 24: pos=(1,3), dirty=False, action=suck\n",
            "Step 25: pos=(1,3), dirty=False, action=east\n",
            "Step 26: pos=(1,4), dirty=False, action=west\n",
            "Step 27: pos=(1,3), dirty=False, action=south\n",
            "Step 28: pos=(2,3), dirty=False, action=west\n",
            "Step 29: pos=(2,2), dirty=False, action=west\n",
            "Step 30: pos=(2,1), dirty=False, action=north\n",
            "Step 31: pos=(1,1), dirty=False, action=east\n",
            "Step 32: pos=(1,2), dirty=False, action=west\n",
            "Step 33: pos=(1,1), dirty=False, action=west\n",
            "Step 34: pos=(1,0), dirty=False, action=suck\n",
            "Step 35: pos=(1,0), dirty=False, action=north\n",
            "Step 36: pos=(0,0), dirty=False, action=suck\n",
            "Step 37: pos=(0,0), dirty=False, action=west\n",
            "Step 38: pos=(0,0), dirty=False, action=suck\n",
            "Step 39: pos=(0,0), dirty=False, action=suck\n",
            "Step 40: pos=(0,0), dirty=False, action=north\n",
            "Step 41: pos=(0,0), dirty=False, action=east\n",
            "Step 42: pos=(0,1), dirty=False, action=suck\n",
            "Step 43: pos=(0,1), dirty=False, action=west\n",
            "Step 44: pos=(0,0), dirty=False, action=suck\n",
            "Step 45: pos=(0,0), dirty=False, action=suck\n",
            "Step 46: pos=(0,0), dirty=False, action=south\n",
            "Step 47: pos=(1,0), dirty=False, action=west\n",
            "Step 48: pos=(1,0), dirty=False, action=west\n",
            "Step 49: pos=(1,0), dirty=False, action=south\n",
            "Step 50: pos=(2,0), dirty=False, action=west\n",
            "Step 51: pos=(2,0), dirty=False, action=east\n",
            "Step 52: pos=(2,1), dirty=False, action=west\n",
            "Step 53: pos=(2,0), dirty=False, action=south\n",
            "Step 54: pos=(3,0), dirty=True, action=south\n",
            "Step 55: pos=(4,0), dirty=True, action=north\n",
            "Step 56: pos=(3,0), dirty=True, action=north\n",
            "Step 57: pos=(2,0), dirty=False, action=south\n",
            "Step 58: pos=(3,0), dirty=True, action=east\n",
            "Step 59: pos=(3,1), dirty=True, action=east\n",
            "Step 60: pos=(3,2), dirty=False, action=west\n",
            "Step 61: pos=(3,1), dirty=True, action=east\n",
            "Step 62: pos=(3,2), dirty=False, action=suck\n",
            "Step 63: pos=(3,2), dirty=False, action=south\n",
            "Step 64: pos=(4,2), dirty=False, action=suck\n",
            "Step 65: pos=(4,2), dirty=False, action=south\n",
            "Step 66: pos=(4,2), dirty=False, action=east\n",
            "Step 67: pos=(4,3), dirty=False, action=north\n",
            "Step 68: pos=(3,3), dirty=False, action=north\n",
            "Step 69: pos=(2,3), dirty=False, action=west\n",
            "Step 70: pos=(2,2), dirty=False, action=west\n",
            "Step 71: pos=(2,1), dirty=False, action=north\n",
            "Step 72: pos=(1,1), dirty=False, action=north\n",
            "Step 73: pos=(0,1), dirty=False, action=east\n",
            "Step 74: pos=(0,2), dirty=False, action=east\n",
            "Step 75: pos=(0,3), dirty=False, action=north\n",
            "Step 76: pos=(0,3), dirty=False, action=west\n",
            "Step 77: pos=(0,2), dirty=False, action=suck\n",
            "Step 78: pos=(0,2), dirty=False, action=suck\n",
            "Step 79: pos=(0,2), dirty=False, action=south\n",
            "Step 80: pos=(1,2), dirty=False, action=east\n",
            "Step 81: pos=(1,3), dirty=False, action=east\n",
            "Step 82: pos=(1,4), dirty=False, action=north\n",
            "Step 83: pos=(0,4), dirty=True, action=south\n",
            "Step 84: pos=(1,4), dirty=False, action=west\n",
            "Step 85: pos=(1,3), dirty=False, action=west\n",
            "Step 86: pos=(1,2), dirty=False, action=west\n",
            "Step 87: pos=(1,1), dirty=False, action=east\n",
            "Step 88: pos=(1,2), dirty=False, action=west\n",
            "Step 89: pos=(1,1), dirty=False, action=east\n",
            "Step 90: pos=(1,2), dirty=False, action=south\n",
            "Step 91: pos=(2,2), dirty=False, action=south\n",
            "Step 92: pos=(3,2), dirty=False, action=south\n",
            "Step 93: pos=(4,2), dirty=False, action=south\n",
            "Step 94: pos=(4,2), dirty=False, action=north\n",
            "Step 95: pos=(3,2), dirty=False, action=south\n",
            "Step 96: pos=(4,2), dirty=False, action=south\n",
            "Step 97: pos=(4,2), dirty=False, action=south\n",
            "Step 98: pos=(4,2), dirty=False, action=west\n",
            "Step 99: pos=(4,1), dirty=False, action=west\n",
            "Total steps: 100\n"
          ]
        }
      ],
      "source": [
        "# Hàm agent mẫu (random, không thông minh)\n",
        "def simple_randomized_agent(bumpers, dirty):\n",
        "    return np.random.choice(ACTIONS)\n",
        "\n",
        "# Thử chạy mô phỏng\n",
        "steps_used = vacuum_environment(simple_randomized_agent, n=5, p=0.2, max_steps=100, verbose=True)\n",
        "print(\"Total steps:\", steps_used)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cVTCq0GTwdM"
      },
      "source": [
        "## Task 2:  Implement a simple reflex agent [10 Points]\n",
        "\n",
        "The simple reflex agent randomly walks around but reacts to the bumper sensor by not bumping into the wall and to dirt with sucking. Implement the agent program as a function.\n",
        "\n",
        "_Note:_ Agents cannot directly use variable in the environment. They only gets the percepts as the arguments to the agent function. Use the function signature for the `simple_randomized_agent` function above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ3LICdWTwdN"
      },
      "outputs": [],
      "source": [
        "# Your code and description goes here\n",
        "import random\n",
        "\n",
        "def simple_reflex_agent(percept):\n",
        "    \"\"\"\n",
        "    Một chương trình tác nhân phản xạ đơn giản.\n",
        "\n",
        "    Tham số:\n",
        "    percept (dict): Một dictionary chứa tri giác của tác nhân từ môi trường, bao gồm\n",
        "                    'is_dirty' (bool), 'can_move' (dict với các hướng di chuyển), và\n",
        "                    'location' (tuple).\n",
        "\n",
        "    Trả về:\n",
        "    str: Một hành động ('Suck', 'Move', hoặc 'NoOp').\n",
        "    \"\"\"\n",
        "    # Bước 1: Kiểm tra xem có bụi bẩn ở vị trí hiện tại không.\n",
        "    if percept['is_dirty']:\n",
        "        return 'Suck'\n",
        "\n",
        "    # Bước 2: Kiểm tra các hướng di chuyển có thể có.\n",
        "    # Tác nhân sẽ tránh di chuyển vào tường (bumper sensor).\n",
        "    # 'can_move' là một dictionary với các hướng (key) và giá trị bool (value).\n",
        "\n",
        "    # Lấy ra danh sách các hướng di chuyển hợp lệ.\n",
        "    valid_moves = [direction for direction, can_move in percept['can_move'].items() if can_move]\n",
        "\n",
        "    # Bước 3: Đưa ra quyết định dựa trên các quy tắc phản xạ.\n",
        "    if valid_moves:\n",
        "        # Nếu có các hướng di chuyển hợp lệ, chọn ngẫu nhiên một hướng.\n",
        "        return random.choice(valid_moves)\n",
        "    else:\n",
        "        # Nếu không có hướng di chuyển hợp lệ nào, không làm gì cả.\n",
        "        return 'NoOp'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMA0yyacTwdN"
      },
      "source": [
        "Show how the agent works with your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHdxM-0UTwdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc732d85-06cb-4444-f127-d478bf6f7826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Môi trường được khởi tạo:\n",
            "[['R' '1' '1' '0' '0']\n",
            " ['0' '1' '0' '1' '1']\n",
            " ['1' '0' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 1: Tại (0, 0), robot hút bụi.\n",
            "[['R' '1' '1' '0' '0']\n",
            " ['0' '1' '0' '1' '1']\n",
            " ['1' '0' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 2: Robot di chuyển xuống từ (0, 0) tới (1, 0).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['R' '1' '0' '1' '1']\n",
            " ['1' '0' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 3: Robot di chuyển phải từ (1, 0) tới (1, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' 'R' '0' '1' '1']\n",
            " ['1' '0' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 4: Tại (1, 1), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' 'R' '0' '1' '1']\n",
            " ['1' '0' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 5: Robot di chuyển xuống từ (1, 1) tới (2, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' 'R' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 6: Robot di chuyển xuống từ (2, 1) tới (3, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' '0' '1' '0' '1']\n",
            " ['0' 'R' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 7: Robot di chuyển lên từ (3, 1) tới (2, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' 'R' '1' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 8: Robot di chuyển phải từ (2, 1) tới (2, 2).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' '0' 'R' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 9: Tại (2, 2), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' '0' 'R' '0' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 10: Robot di chuyển phải từ (2, 2) tới (2, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' '0' '0' 'R' '1']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 11: Robot di chuyển phải từ (2, 3) tới (2, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 12: Tại (2, 4), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' '1']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 13: Robot di chuyển lên từ (2, 4) tới (1, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' 'R']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 14: Tại (1, 4), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '1' 'R']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 15: Robot di chuyển trái từ (1, 4) tới (1, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 16: Tại (1, 3), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 17: Robot di chuyển phải từ (1, 3) tới (1, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 18: Robot di chuyển xuống từ (1, 4) tới (2, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 19: Robot di chuyển trái từ (2, 4) tới (2, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' 'R' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 20: Robot di chuyển trái từ (2, 3) tới (2, 2).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' 'R' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 21: Robot di chuyển phải từ (2, 2) tới (2, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' 'R' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 22: Robot di chuyển lên từ (2, 3) tới (1, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 23: Robot di chuyển phải từ (1, 3) tới (1, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 24: Robot di chuyển xuống từ (1, 4) tới (2, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 25: Robot di chuyển trái từ (2, 4) tới (2, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' 'R' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 26: Robot di chuyển xuống từ (2, 3) tới (3, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' 'R' '0']\n",
            " ['0' '0' '1' '0' '1']]\n",
            "------------------------------\n",
            "Bước 27: Robot di chuyển xuống từ (3, 3) tới (4, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' 'R' '1']]\n",
            "------------------------------\n",
            "Bước 28: Robot di chuyển phải từ (4, 3) tới (4, 4).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' 'R']]\n",
            "------------------------------\n",
            "Bước 29: Tại (4, 4), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' '0' 'R']]\n",
            "------------------------------\n",
            "Bước 30: Robot di chuyển trái từ (4, 4) tới (4, 3).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' '1' 'R' '0']]\n",
            "------------------------------\n",
            "Bước 31: Robot di chuyển trái từ (4, 3) tới (4, 2).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']]\n",
            "------------------------------\n",
            "Bước 32: Tại (4, 2), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '1' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']]\n",
            "------------------------------\n",
            "Bước 33: Robot di chuyển lên từ (4, 2) tới (3, 2).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 34: Tại (3, 2), robot hút bụi.\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 35: Robot di chuyển trái từ (3, 2) tới (3, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 36: Robot di chuyển trái từ (3, 1) tới (3, 0).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['R' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 37: Robot di chuyển xuống từ (3, 0) tới (4, 0).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['R' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 38: Robot di chuyển phải từ (4, 0) tới (4, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 39: Robot di chuyển phải từ (4, 1) tới (4, 2).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']]\n",
            "------------------------------\n",
            "Bước 40: Robot di chuyển trái từ (4, 2) tới (4, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 41: Robot di chuyển phải từ (4, 1) tới (4, 2).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']]\n",
            "------------------------------\n",
            "Bước 42: Robot di chuyển trái từ (4, 2) tới (4, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 43: Robot di chuyển lên từ (4, 1) tới (3, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 44: Robot di chuyển lên từ (3, 1) tới (2, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 45: Robot di chuyển lên từ (2, 1) tới (1, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 46: Robot di chuyển xuống từ (1, 1) tới (2, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 47: Robot di chuyển xuống từ (2, 1) tới (3, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 48: Robot di chuyển lên từ (3, 1) tới (2, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 49: Robot di chuyển lên từ (2, 1) tới (1, 1).\n",
            "[['0' '1' '1' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 50: Robot di chuyển lên từ (1, 1) tới (0, 1).\n",
            "[['0' 'R' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 51: Tại (0, 1), robot hút bụi.\n",
            "[['0' 'R' '1' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 52: Robot di chuyển phải từ (0, 1) tới (0, 2).\n",
            "[['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 53: Tại (0, 2), robot hút bụi.\n",
            "[['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 54: Robot di chuyển phải từ (0, 2) tới (0, 3).\n",
            "[['0' '0' '0' 'R' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 55: Robot di chuyển trái từ (0, 3) tới (0, 2).\n",
            "[['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 56: Robot di chuyển trái từ (0, 2) tới (0, 1).\n",
            "[['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 57: Robot di chuyển xuống từ (0, 1) tới (1, 1).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 58: Robot di chuyển lên từ (1, 1) tới (0, 1).\n",
            "[['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 59: Robot di chuyển trái từ (0, 1) tới (0, 0).\n",
            "[['R' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 60: Robot di chuyển xuống từ (0, 0) tới (1, 0).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['R' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 61: Robot di chuyển lên từ (1, 0) tới (0, 0).\n",
            "[['R' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 62: Robot di chuyển xuống từ (0, 0) tới (1, 0).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['R' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 63: Robot di chuyển lên từ (1, 0) tới (0, 0).\n",
            "[['R' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 64: Robot di chuyển phải từ (0, 0) tới (0, 1).\n",
            "[['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 65: Robot di chuyển trái từ (0, 1) tới (0, 0).\n",
            "[['R' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 66: Robot di chuyển phải từ (0, 0) tới (0, 1).\n",
            "[['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 67: Robot di chuyển trái từ (0, 1) tới (0, 0).\n",
            "[['R' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 68: Robot di chuyển phải từ (0, 0) tới (0, 1).\n",
            "[['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 69: Robot di chuyển phải từ (0, 1) tới (0, 2).\n",
            "[['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 70: Robot di chuyển phải từ (0, 2) tới (0, 3).\n",
            "[['0' '0' '0' 'R' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 71: Robot di chuyển trái từ (0, 3) tới (0, 2).\n",
            "[['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 72: Robot di chuyển xuống từ (0, 2) tới (1, 2).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 73: Robot di chuyển phải từ (1, 2) tới (1, 3).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 74: Robot di chuyển xuống từ (1, 3) tới (2, 3).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' 'R' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 75: Robot di chuyển phải từ (2, 3) tới (2, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 76: Robot di chuyển xuống từ (2, 4) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 77: Robot di chuyển xuống từ (3, 4) tới (4, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']]\n",
            "------------------------------\n",
            "Bước 78: Robot di chuyển lên từ (4, 4) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 79: Robot di chuyển xuống từ (3, 4) tới (4, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']]\n",
            "------------------------------\n",
            "Bước 80: Robot di chuyển lên từ (4, 4) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 81: Robot di chuyển lên từ (3, 4) tới (2, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 82: Robot di chuyển xuống từ (2, 4) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 83: Robot di chuyển xuống từ (3, 4) tới (4, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']]\n",
            "------------------------------\n",
            "Bước 84: Robot di chuyển trái từ (4, 4) tới (4, 3).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']]\n",
            "------------------------------\n",
            "Bước 85: Robot di chuyển lên từ (4, 3) tới (3, 3).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 86: Robot di chuyển trái từ (3, 3) tới (3, 2).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 87: Robot di chuyển phải từ (3, 2) tới (3, 3).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 88: Robot di chuyển phải từ (3, 3) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 89: Robot di chuyển lên từ (3, 4) tới (2, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 90: Robot di chuyển xuống từ (2, 4) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 91: Robot di chuyển xuống từ (3, 4) tới (4, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']]\n",
            "------------------------------\n",
            "Bước 92: Robot di chuyển lên từ (4, 4) tới (3, 4).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' 'R']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 93: Robot di chuyển trái từ (3, 4) tới (3, 3).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' 'R' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 94: Robot di chuyển trái từ (3, 3) tới (3, 2).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 95: Robot di chuyển trái từ (3, 2) tới (3, 1).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 96: Robot di chuyển phải từ (3, 1) tới (3, 2).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 97: Robot di chuyển lên từ (3, 2) tới (2, 2).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' 'R' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 98: Robot di chuyển trái từ (2, 2) tới (2, 1).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 99: Robot di chuyển xuống từ (2, 1) tới (3, 1).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']]\n",
            "------------------------------\n",
            "Bước 100: Robot di chuyển xuống từ (3, 1) tới (4, 1).\n",
            "[['0' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['1' '0' '0' '0' '0']\n",
            " ['0' '0' '0' '0' '0']\n",
            " ['0' 'R' '0' '0' '0']]\n",
            "------------------------------\n",
            "Đã đạt đến số bước tối đa (100). Nhiệm vụ chưa hoàn thành.\n"
          ]
        }
      ],
      "source": [
        "# Your code and description goes here\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Tác nhân đã triển khai ở yêu cầu trước.\n",
        "def simple_reflex_agent(percept):\n",
        "    \"\"\"\n",
        "    Một chương trình tác nhân phản xạ đơn giản.\n",
        "    \"\"\"\n",
        "    if percept['is_dirty']:\n",
        "        return 'Suck'\n",
        "\n",
        "    valid_moves = [direction for direction, can_move in percept['can_move'].items() if can_move]\n",
        "\n",
        "    if valid_moves:\n",
        "        return random.choice(valid_moves)\n",
        "    else:\n",
        "        return 'NoOp'\n",
        "\n",
        "# Môi trường mô phỏng được triển khai để kiểm tra tác nhân\n",
        "def simple_environment(agent_program, room_size=(5, 5), initial_dirt_ratio=0.5, max_steps=100, verbose=True):\n",
        "    \"\"\"\n",
        "    Mô phỏng một môi trường phòng đơn giản.\n",
        "\n",
        "    Tham số:\n",
        "    agent_program (function): Hàm tác nhân được sử dụng để điều khiển robot.\n",
        "    room_size (tuple): Kích thước của phòng (hàng, cột).\n",
        "    initial_dirt_ratio (float): Tỷ lệ phần trăm các ô ban đầu bị bẩn.\n",
        "    max_steps (int): Số bước tối đa trước khi dừng mô phỏng.\n",
        "    verbose (bool): Nếu True, sẽ in ra trạng thái chi tiết của quá trình mô phỏng.\n",
        "\n",
        "    Trả về:\n",
        "    int: Số bước mà tác nhân đã thực hiện để hoàn thành nhiệm vụ.\n",
        "    \"\"\"\n",
        "    rows, cols = room_size\n",
        "\n",
        "    # 1. Khởi tạo môi trường\n",
        "    # Tạo phòng sạch hoàn toàn (0 = sạch, 1 = bẩn)\n",
        "    room = np.zeros(room_size, dtype=int)\n",
        "\n",
        "    # Làm bẩn ngẫu nhiên một số ô\n",
        "    num_dirty_squares = int(rows * cols * initial_dirt_ratio)\n",
        "    dirty_indices = np.random.choice(range(rows * cols), num_dirty_squares, replace=False)\n",
        "    for index in dirty_indices:\n",
        "        room.flat[index] = 1\n",
        "\n",
        "    # Vị trí ban đầu của robot\n",
        "    robot_pos = (0, 0)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Môi trường được khởi tạo:\")\n",
        "        display_room(room, robot_pos)\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    # Vòng lặp chính của môi trường\n",
        "    action_count = 0\n",
        "    while np.any(room == 1) and action_count < max_steps:\n",
        "        # 2. Cung cấp tri giác cho tác nhân\n",
        "        is_dirty = room[robot_pos] == 1\n",
        "\n",
        "        can_move = {\n",
        "            'up': robot_pos[0] > 0,\n",
        "            'down': robot_pos[0] < rows - 1,\n",
        "            'left': robot_pos[1] > 0,\n",
        "            'right': robot_pos[1] < cols - 1\n",
        "        }\n",
        "\n",
        "        percept = {\n",
        "            'is_dirty': is_dirty,\n",
        "            'can_move': can_move,\n",
        "            'location': robot_pos\n",
        "        }\n",
        "\n",
        "        # 3. Gọi chương trình tác nhân\n",
        "        action = agent_program(percept)\n",
        "\n",
        "        # 4. Phản ứng với hành động của tác nhân\n",
        "        new_pos = robot_pos\n",
        "        if action == 'Suck':\n",
        "            room[robot_pos] = 0\n",
        "            if verbose:\n",
        "                print(f\"Bước {action_count + 1}: Tại {robot_pos}, robot hút bụi.\")\n",
        "        elif action == 'up' and can_move['up']:\n",
        "            new_pos = (robot_pos[0] - 1, robot_pos[1])\n",
        "            if verbose:\n",
        "                print(f\"Bước {action_count + 1}: Robot di chuyển lên từ {robot_pos} tới {new_pos}.\")\n",
        "        elif action == 'down' and can_move['down']:\n",
        "            new_pos = (robot_pos[0] + 1, robot_pos[1])\n",
        "            if verbose:\n",
        "                print(f\"Bước {action_count + 1}: Robot di chuyển xuống từ {robot_pos} tới {new_pos}.\")\n",
        "        elif action == 'left' and can_move['left']:\n",
        "            new_pos = (robot_pos[0], robot_pos[1] - 1)\n",
        "            if verbose:\n",
        "                print(f\"Bước {action_count + 1}: Robot di chuyển trái từ {robot_pos} tới {new_pos}.\")\n",
        "        elif action == 'right' and can_move['right']:\n",
        "            new_pos = (robot_pos[0], robot_pos[1] + 1)\n",
        "            if verbose:\n",
        "                print(f\"Bước {action_count + 1}: Robot di chuyển phải từ {robot_pos} tới {new_pos}.\")\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(f\"Bước {action_count + 1}: Robot không làm gì (hành động: {action}).\")\n",
        "\n",
        "        robot_pos = new_pos\n",
        "        action_count += 1\n",
        "\n",
        "        if verbose:\n",
        "            display_room(room, robot_pos)\n",
        "            time.sleep(0.5) # Dừng một chút để dễ theo dõi\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "    # 5. Ghi nhận hiệu suất\n",
        "    if not np.any(room == 1):\n",
        "        if verbose:\n",
        "            print(f\"Nhiệm vụ hoàn thành! Robot đã mất {action_count} bước để làm sạch phòng.\")\n",
        "        return action_count\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"Đã đạt đến số bước tối đa ({max_steps}). Nhiệm vụ chưa hoàn thành.\")\n",
        "        return max_steps\n",
        "\n",
        "def display_room(room, robot_pos):\n",
        "    \"\"\"Hàm trợ giúp để hiển thị trạng thái phòng.\"\"\"\n",
        "    display_grid = np.array(room, dtype='<U2')\n",
        "    display_grid[robot_pos] = 'R'\n",
        "    print(display_grid)\n",
        "\n",
        "# Chạy mô phỏng\n",
        "final_steps = simple_environment(simple_reflex_agent, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cách hoạt động của tác nhân và môi trường\n",
        "\n",
        "Triển khai trên minh họa một vòng lặp tác nhân-môi trường. Đây là cốt lõi của việc mô phỏng một hệ thống tác nhân:\n",
        "\n",
        "Khởi tạo: Môi trường (simple_environment) thiết lập trạng thái ban đầu của căn phòng (sạch/bẩn) và vị trí của robot.\n",
        "\n",
        "Vòng lặp: Mô phỏng chạy trong một vòng lặp while cho đến khi tất cả bụi bẩn được dọn sạch hoặc đạt đến giới hạn số bước.\n",
        "\n",
        "Cảm biến (Percept): Ở mỗi bước, môi trường thu thập các thông tin cần thiết (ô hiện tại có bẩn không, có thể di chuyển không) và đóng gói chúng thành một tri giác (percept).\n",
        "\n",
        "Hành động (Action): Tri giác này được truyền làm đầu vào cho hàm tác nhân (simple_reflex_agent). Tác nhân, chỉ dựa vào tri giác đó, sẽ đưa ra một hành động ('Suck', 'Move', 'NoOp').\n",
        "\n",
        "Phản ứng (Reaction): Môi trường nhận hành động đó và cập nhật trạng thái của nó (làm sạch ô, di chuyển robot).\n",
        "\n",
        "Quá trình này lặp đi lặp lại. Việc sử dụng hàm display_room và verbose giúp bạn dễ dàng theo dõi cách tác nhân đưa ra quyết định và phản ứng của môi trường sau mỗi bước."
      ],
      "metadata": {
        "id": "CehhdB_dLAr4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDDLz2BzTwdO"
      },
      "source": [
        "## Task 3: Implement a model-based reflex agent [20 Points]\n",
        "\n",
        "Model-based agents use a state to keep track of what they have done and perceived so far. Your agent needs to find out where it is located and then keep track of its current location. You also need a set of rules based on the state and the percepts to make sure that the agent will clean the whole room. For example, the agent can move to a corner to determine its location and then it can navigate through the whole room and clean dirty squares.\n",
        "\n",
        "Describe how you define the __agent state__ and how your agent works before implementing it. ([Help with implementing state information on Python](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tác nhân phản xạ dựa trên mô hình (model-based reflex agent) này được thiết kế để làm sạch căn phòng một cách có hệ thống thay vì di chuyển ngẫu nhiên. Để làm được điều này, nó duy trì một trạng thái nội bộ để theo dõi thông tin về thế giới.\n",
        "** Trạng thái Tác nhân (Agent State)\n",
        "- Trạng thái của tác nhân được lưu trữ trong một dictionary Python và bao gồm các thông tin sau:\n",
        "     + 'localized': Một biến boolean (True/False). Ban đầu là False. Nó sẽ trở thành True khi tác nhân đã xác định được vị trí của mình trong phòng.\n",
        "     + 'location': Một tuple (x, y) biểu diễn tọa độ hiện tại của tác nhân. Ban đầu là None. Góc Tây-Bắc (trên-trái) được định nghĩa là (0, 0).\n",
        "     + 'direction': Một chuỗi ('east' hoặc 'west') chỉ định hướng di chuyển hiện tại trong quá trình làm sạch theo hàng.\n",
        "     + 'room_size': Một số nguyên n đại diện cho kích thước của căn phòng n x n. Tác nhân biết thông tin này trước.\n",
        "** Logic hoạt động\n",
        "- Tác nhân hoạt động theo hai giai đoạn riêng biệt:\n",
        "1. Giai đoạn Định vị (Localization Phase):\n",
        "     + Nếu trạng thái 'localized' là False, mục tiêu duy nhất của tác nhân là đi đến một góc tham chiếu đã biết.\n",
        "     + Nó sẽ liên tục di chuyển về hướng west cho đến khi cảm biến va chạm bumpers['west'] báo hiệu đã chạm tường.\n",
        "     + Sau đó, nó sẽ liên tục di chuyển về hướng north cho đến khi cảm biến va chạm bumpers['north'] báo hiệu đã chạm tường.\n",
        "     + Khi cả hai điều kiện trên được thỏa mãn, tác nhân biết rằng nó đang ở góc Tây-Bắc (0, 0).\n",
        "     + Nó cập nhật trạng thái: 'localized' thành True, 'location' thành (0, 0), và đặt hướng di chuyển ban đầu 'direction' là 'east'.\n",
        "2. Giai đoạn Dọn dẹp (Cleaning Phase):\n",
        "     + Một khi đã được định vị, tác nhân sẽ bắt đầu quá trình dọn dẹp có hệ thống.\n",
        "     + Ưu tiên hàng đầu: Nếu cảm biến báo dirty (bẩn), hành động sẽ luôn là 'suck'. Tác nhân sẽ không di chuyển cho đến khi ô hiện tại đã sạch.\n",
        "     + Di chuyển theo Mẫu (Pattern Movement): Nếu ô hiện tại đã sạch, tác nhân sẽ di chuyển theo một mẫu \"cày ruộng\" (boustrophedon):\n",
        "          + Nếu hướng hiện tại là 'east', nó sẽ di chuyển sang phải cho đến khi chạm tường phía đông (x == n-1).\n",
        "          + Khi chạm tường phía đông, nó sẽ di chuyển xuống một ô ('south') và đổi hướng thành 'west'.\n",
        "          + Nếu hướng hiện tại là 'west', nó sẽ di chuyển sang trái cho đến khi chạm tường phía tây (x == 0).\n",
        "          + Khi chạm tường phía tây, nó sẽ di chuyển xuống một ô ('south') và đổi hướng thành 'east'.\n",
        "     + Quá trình này đảm bảo tác nhân sẽ đi qua mọi ô trong phòng một cách hiệu quả. Sau mỗi hành động di chuyển, tác nhân sẽ cập nhật tọa độ 'location' trong trạng thái nội bộ của mình."
      ],
      "metadata": {
        "id": "7njReVrMJySz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8OjQifnTwdP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "agent_state = {}\n",
        "\n",
        "def reset_model_based_agent_state(n=5):\n",
        "    global agent_state\n",
        "    agent_state = {\n",
        "        'localized': False,\n",
        "        'location': None,\n",
        "        'direction': 'east',\n",
        "        'room_size': n\n",
        "    }\n",
        "\n",
        "def model_based_reflex_agent(bumpers, dirty):\n",
        "    global agent_state\n",
        "\n",
        "    if not agent_state['localized']:\n",
        "        if not bumpers['west']:\n",
        "            return 'west'\n",
        "        if not bumpers['north']:\n",
        "            return 'north'\n",
        "\n",
        "        agent_state['localized'] = True\n",
        "        agent_state['location'] = (0, 0)\n",
        "\n",
        "        return 'suck'\n",
        "\n",
        "    if dirty:\n",
        "        return 'suck'\n",
        "\n",
        "    x, y = agent_state['location']\n",
        "    n = agent_state['room_size']\n",
        "    direction = agent_state['direction']\n",
        "    action = None\n",
        "\n",
        "    if direction == 'east':\n",
        "        if x < n - 1:\n",
        "            action = 'east'\n",
        "            agent_state['location'] = (x + 1, y)\n",
        "        else:\n",
        "            action = 'south'\n",
        "            agent_state['location'] = (x, y + 1)\n",
        "            agent_state['direction'] = 'west'\n",
        "    elif direction == 'west':\n",
        "        if x > 0:\n",
        "            action = 'west'\n",
        "            agent_state['location'] = (x - 1, y)\n",
        "        else:\n",
        "            action = 'south'\n",
        "            agent_state['location'] = (x, y + 1)\n",
        "            agent_state['direction'] = 'east'\n",
        "\n",
        "    current_y = agent_state['location'][1]\n",
        "    if current_y >= n:\n",
        "        return 'suck'\n",
        "\n",
        "    return action\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_X8f_7TwdP"
      },
      "source": [
        "Show how the agent works with your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGDGyoYFTwdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cd7657-5562-4429-ecb2-6a505e6cac63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Model-Based Reflex Agent ---\n",
            "Step 1\n",
            "[['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' 'R' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 3), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: west\n",
            "Step 2\n",
            "[['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'R' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 2), Dirty: True, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: west\n",
            "Step 3\n",
            "[['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'R' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 1), Dirty: True, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: west\n",
            "Step 4\n",
            "[['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['R' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 0), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': True, 'east': False}\n",
            "Action: north\n",
            "Step 5\n",
            "[['.' 'D' 'D' '.' '.']\n",
            " ['R' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 0), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': True, 'east': False}\n",
            "Action: north\n",
            "Step 6\n",
            "[['R' 'D' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 0), Dirty: False, Bumpers: {'north': True, 'south': False, 'west': True, 'east': False}\n",
            "Action: suck\n",
            "Step 7\n",
            "[['R' 'D' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 0), Dirty: False, Bumpers: {'north': True, 'south': False, 'west': True, 'east': False}\n",
            "Action: east\n",
            "Step 8\n",
            "[['.' 'R' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 1), Dirty: True, Bumpers: {'north': True, 'south': False, 'west': False, 'east': False}\n",
            "Action: suck\n",
            "Step 9\n",
            "[['.' 'R' 'D' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 1), Dirty: False, Bumpers: {'north': True, 'south': False, 'west': False, 'east': False}\n",
            "Action: east\n",
            "Step 10\n",
            "[['.' '.' 'R' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 2), Dirty: True, Bumpers: {'north': True, 'south': False, 'west': False, 'east': False}\n",
            "Action: suck\n",
            "Step 11\n",
            "[['.' '.' 'R' '.' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 2), Dirty: False, Bumpers: {'north': True, 'south': False, 'west': False, 'east': False}\n",
            "Action: east\n",
            "Step 12\n",
            "[['.' '.' '.' 'R' '.']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 3), Dirty: False, Bumpers: {'north': True, 'south': False, 'west': False, 'east': False}\n",
            "Action: east\n",
            "Step 13\n",
            "[['.' '.' '.' '.' 'R']\n",
            " ['.' '.' 'D' '.' 'D']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (0, 4), Dirty: False, Bumpers: {'north': True, 'south': False, 'west': False, 'east': True}\n",
            "Action: south\n",
            "Step 14\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'D' '.' 'R']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 4), Dirty: True, Bumpers: {'north': False, 'south': False, 'west': False, 'east': True}\n",
            "Action: suck\n",
            "Step 15\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'D' '.' 'R']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 4), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': False, 'east': True}\n",
            "Action: west\n",
            "Step 16\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'D' 'R' '.']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 3), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: west\n",
            "Step 17\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'R' '.' '.']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 2), Dirty: True, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: suck\n",
            "Step 18\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'R' '.' '.']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 2), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: west\n",
            "Step 19\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' 'R' '.' '.' '.']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 1), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: west\n",
            "Step 20\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['R' '.' '.' '.' '.']\n",
            " ['.' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (1, 0), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': True, 'east': False}\n",
            "Action: south\n",
            "Step 21\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['R' 'D' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 0), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': True, 'east': False}\n",
            "Action: east\n",
            "Step 22\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' 'R' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 1), Dirty: True, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: suck\n",
            "Step 23\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' 'R' 'D' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 1), Dirty: False, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: east\n",
            "Step 24\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'R' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "Agent position (row, col): (2, 2), Dirty: True, Bumpers: {'north': False, 'south': False, 'west': False, 'east': False}\n",
            "Action: suck\n",
            "Step 25\n",
            "[['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' 'R' '.' '.']\n",
            " ['.' '.' '.' '.' '.']\n",
            " ['.' '.' '.' '.' '.']]\n",
            "----------\n",
            "\n",
            "All squares are clean! Task finished.\n",
            "\n",
            "Total actions taken (Performance): 24\n"
          ]
        }
      ],
      "source": [
        "def environment(agent_function, n=5, p=0.2, max_steps=200, verbose=True):\n",
        "    room = np.random.choice([0, 1], size=(n, n), p=[1-p, p])\n",
        "    agent_pos = [np.random.randint(0, n), np.random.randint(0, n)]\n",
        "\n",
        "    performance = 0\n",
        "\n",
        "    def display_room(room_state, pos):\n",
        "        grid = room_state.astype(str)\n",
        "        grid[grid == '0'] = '.'\n",
        "        grid[grid == '1'] = 'D'\n",
        "        if 0 <= pos[0] < n and 0 <= pos[1] < n:\n",
        "            grid[pos[0], pos[1]] = 'R'\n",
        "        print(grid)\n",
        "        print(\"-\" * n * 2)\n",
        "\n",
        "    for i in range(max_steps):\n",
        "        if verbose:\n",
        "            print(f\"Step {i+1}\")\n",
        "            display_room(room, agent_pos)\n",
        "\n",
        "        if np.sum(room) == 0:\n",
        "            if verbose:\n",
        "                print(f\"\\nAll squares are clean! Task finished.\")\n",
        "            return performance\n",
        "\n",
        "        performance += 1\n",
        "\n",
        "        row, col = agent_pos\n",
        "\n",
        "        bumpers = {\n",
        "            \"north\": row == 0,\n",
        "            \"south\": row == n - 1,\n",
        "            \"west\": col == 0,\n",
        "            \"east\": col == n - 1\n",
        "        }\n",
        "\n",
        "        dirty = (room[row, col] == 1)\n",
        "\n",
        "        action = agent_function(bumpers, dirty)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Agent position (row, col): {tuple(agent_pos)}, Dirty: {dirty}, Bumpers: {bumpers}\")\n",
        "            print(f\"Action: {action}\")\n",
        "\n",
        "        if action == \"suck\":\n",
        "            room[row, col] = 0\n",
        "        elif action == \"north\" and not bumpers[\"north\"]:\n",
        "            agent_pos[0] -= 1\n",
        "        elif action == \"south\" and not bumpers[\"south\"]:\n",
        "            agent_pos[0] += 1\n",
        "        elif action == \"west\" and not bumpers[\"west\"]:\n",
        "            agent_pos[1] -= 1\n",
        "        elif action == \"east\" and not bumpers[\"east\"]:\n",
        "            agent_pos[1] += 1\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nMax steps reached. Task failed.\")\n",
        "    return performance\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Running Model-Based Reflex Agent ---\")\n",
        "    reset_model_based_agent_state(n=5)\n",
        "    np.random.seed(42)\n",
        "    score = environment(model_based_reflex_agent, n=5, p=0.3, max_steps=100, verbose=True)\n",
        "    print(f\"\\nTotal actions taken (Performance): {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjGcqRCLTwdQ"
      },
      "source": [
        "## Task 4: Simulation study [30 Points]\n",
        "\n",
        "Compare the performance (the performance measure is defined in the PEAS description above) of the agents using  environments of different size. Do at least $5 \\times 5$, $10 \\times 10$ and\n",
        "$100 \\times 100$. Use 100 random runs for each. Present the results using tables and graphs. Discuss the differences between the agents.\n",
        "([Help with charts and tables in Python](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/charts_and_tables.ipynb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbsyI78KTwdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf161ce-86ce-4c42-80cf-fe23de220727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running simulations...\n",
            "Size\tRandom\tReflex\tModel-based\n",
            "5x5\t434.2\t90.5\t27.2\n",
            "10x10\t2837.0\t1036.5\t119.9\n",
            "100x100\t20000.0\t20000.0\t12059.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "# ===================== ENVIRONMENT =====================\n",
        "\n",
        "def run_env(agent, n, p=0.2, steps=20000):\n",
        "    room = np.random.rand(n, n) < p\n",
        "    pos = [np.random.randint(n), np.random.randint(n)]\n",
        "    act = 0\n",
        "    while room.any() and act < steps:\n",
        "        b = {\"north\": pos[0]==0, \"south\": pos[0]==n-1,\n",
        "             \"west\": pos[1]==0, \"east\": pos[1]==n-1}\n",
        "        d = room[pos[0], pos[1]]\n",
        "        a = agent(b, d, pos)\n",
        "        if a==\"suck\" and d:\n",
        "            room[pos[0], pos[1]]=False\n",
        "        elif a==\"north\" and not b[\"north\"]:\n",
        "            pos[0]-=1\n",
        "        elif a==\"south\" and not b[\"south\"]:\n",
        "            pos[0]+=1\n",
        "        elif a==\"west\" and not b[\"west\"]:\n",
        "            pos[1]-=1\n",
        "        elif a==\"east\" and not b[\"east\"]:\n",
        "            pos[1]+=1\n",
        "        act+=1\n",
        "    return act\n",
        "\n",
        "\n",
        "# ===================== AGENTS =====================\n",
        "\n",
        "acts=[\"north\",\"south\",\"west\",\"east\",\"suck\"]\n",
        "\n",
        "def ag_ran(b,d,pos):\n",
        "    return np.random.choice(acts)\n",
        "\n",
        "def ag_ref(b,d,pos):\n",
        "    if d: return \"suck\"\n",
        "    dirs=[k for k,v in b.items() if not v]\n",
        "    return np.random.choice(dirs) if dirs else \"suck\"\n",
        "\n",
        "\n",
        "# ===================== MODEL-BASED REFLEX AGENT =====================\n",
        "\n",
        "class AgModel:\n",
        "    def __init__(self,n):\n",
        "        self.n=n\n",
        "        self.known=np.full((n,n),None)  # None=unknown, False=clean, True=dirty\n",
        "        self.path=[]\n",
        "\n",
        "    def bfs(self,start,targets):\n",
        "        n=self.n\n",
        "        q=deque([(start,[])])\n",
        "        seen={tuple(start)}\n",
        "        dirs={\"north\":(-1,0),\"south\":(1,0),\"west\":(0,-1),\"east\":(0,1)}\n",
        "        while q:\n",
        "            (x,y),path=q.popleft()\n",
        "            if (x,y) in targets:\n",
        "                return path\n",
        "            for a,(dx,dy) in dirs.items():\n",
        "                nx,ny=x+dx,y+dy\n",
        "                if 0<=nx<n and 0<=ny<n and (nx,ny) not in seen:\n",
        "                    seen.add((nx,ny))\n",
        "                    q.append(((nx,ny),path+[a]))\n",
        "        return []\n",
        "\n",
        "    def __call__(self,b,d,pos):\n",
        "        x,y=pos\n",
        "        self.known[x,y]=d\n",
        "        if d:\n",
        "            self.path=[]\n",
        "            return \"suck\"\n",
        "        n=self.n\n",
        "        unknowns={(i,j) for i in range(n) for j in range(n) if self.known[i,j] is None}\n",
        "        dirties={(i,j) for i in range(n) for j in range(n) if self.known[i,j]}\n",
        "        if not self.path:\n",
        "            targets=dirties if dirties else unknowns\n",
        "            if targets:\n",
        "                self.path=self.bfs((x,y),targets)\n",
        "        if not self.path:\n",
        "            return \"suck\"\n",
        "        move=self.path.pop(0)\n",
        "        return move\n",
        "\n",
        "\n",
        "# ===================== TEST =====================\n",
        "\n",
        "def test(agent,n,rep=30):\n",
        "    res=[]\n",
        "    for _ in range(rep):\n",
        "        a=agent if agent!=AgModel else AgModel(n)\n",
        "        res.append(run_env(a,n))\n",
        "    return np.mean(res)\n",
        "\n",
        "sizes=[5,10,100]\n",
        "print(\"Running simulations...\")\n",
        "print(\"Size\\tRandom\\tReflex\\tModel-based\")\n",
        "for n in sizes:\n",
        "    res_ran=test(ag_ran,n)\n",
        "    res_ref=test(ag_ref,n)\n",
        "    res_mod=test(AgModel,n)\n",
        "    print(f\"{n}x{n}\\t{res_ran:.1f}\\t{res_ref:.1f}\\t{res_mod:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfZvbOaxTwdR"
      },
      "source": [
        "Fill out the following table with the average performance measure for 100 random runs (you may also create this table with code):\n",
        "\n",
        "| Size     | Randomized Agent | Simple Reflex Agent | Model-based Reflex Agent |\n",
        "|----------|------------------|---------------------|--------------------------|\n",
        "| 5x5     | | | |\n",
        "| 10x10   | | | |\n",
        "| 100x100 | | | |\n",
        "\n",
        "Add charts to compare the performance of the different agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbSNNQpkTwdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d4312593-454c-424c-8596-057f2b8618a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4137549219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Your graphs and discussion of the results goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_ran\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Ran\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Ref\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_mod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Mod\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Your graphs and discussion of the results goes here\n",
        "plt.bar(x-w,res_ran,w,label=\"Ran\")\n",
        "plt.bar(x,res_ref,w,label=\"Ref\")\n",
        "plt.bar(x+w,res_mod,w,label=\"Mod\")\n",
        "plt.xticks(x,sizes)\n",
        "plt.ylabel(\"Avg Actions\")\n",
        "plt.xlabel(\"Room Size\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "import textwrap\n",
        "\n",
        "txt = \"Kết quả cho thấy Simple Reflex agent hoạt động tốt nhất ở phòng nhỏ và trung bình, trong khi Randomized chỉ hiệu quả ở phòng nhỏ, còn Model-based Reflex lại tốn nhiều bước hơn dự kiến. Vậy tại sao Model-based Reflex không vượt trội? Nguyên nhân là do cách xây dựng mô hình chưa tối ưu, khiến agent thực hiện nhiều hành động dư thừa. Ở phòng lớn 100×100, cả ba agent đều đạt giới hạn bước, đặt ra câu hỏi: liệu các chiến lược phản xạ có còn phù hợp với môi trường quá rộng? Câu trả lời là không, và để cải thiện cần hướng đến các phương pháp có khả năng tìm đường và lập kế hoạch tốt hơn. Thực tế, trong robot hút bụi, người ta thường kết hợp cảm biến với bản đồ (mapping) và thuật toán tìm đường để dọn sạch nhanh và hiệu quả hơn thay vì chỉ dựa vào phản xạ.\"\n",
        "\n",
        "print(textwrap.fill(txt, width=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-bUWL-TwdS"
      },
      "source": [
        "## Task 5: Robustness of the agent implementations [10 Points]\n",
        "\n",
        "Describe how **your agent implementations** will perform\n",
        "\n",
        "* if it is put into a rectangular room with unknown size,\n",
        "* if the cleaning area can have an irregular shape (e.g., a hallway connecting two rooms), or\n",
        "* if the room contains obstacles (i.e., squares that it cannot pass through and trigger the bumper sensors).\n",
        "* if the dirt sensor is not perfect and gives 10% of the time a wrong reading (clean when it is dirty or dirty when it is clean).\n",
        "* if the bumper sensor is not perfect and 10% of the time does not report a wall when there is one."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Nếu phòng là hình chữ nhật nhưng không biết kích thước\n",
        "  - Tác nhân Ngẫu nhiên (Randomized Agent): Tác nhân này không quan tâm đến kích thước hay hình dạng của phòng. Nó sẽ tiếp tục di chuyển ngẫu nhiên và va vào tường như bình thường. Hiệu suất của nó vốn đã rất tệ, nên sẽ không có gì thay đổi lớn.\n",
        "  - Tác nhân Phản xạ Đơn giản (Simple Reflex Agent): Tác nhân này hoạt động khá tốt. Nó không cần biết kích thước phòng vì nó chỉ phản ứng với các bức tường ngay trước mặt. Nó sẽ đi lang thang trong phòng hình chữ nhật và dọn dẹp một cách ngẫu nhiên. Nó vẫn không hiệu quả, nhưng nó sẽ không bị \"hỏng\".\n",
        "  - Tác nhân Dựa trên Mô hình (Model-based Reflex Agent): Sẽ thất bại hoàn toàn. Tác nhân này được lập trình với giả định về một căn phòng hình vuông `n x n`. Nếu kích thước thực tế khác đi (ví dụ 5x8 thay vì 5x5), kế hoạch di chuyển theo hàng của nó sẽ sai. Nó sẽ nghĩ rằng nó đã đến cuối hàng trong khi thực tế chưa, làm cho tọa độ nội bộ của nó bị lệch hoàn toàn so với vị trí thực. Kế hoạch dọn dẹp có hệ thống sẽ sụp đổ.\n",
        "2. Nếu khu vực dọn dẹp có hình dạng bất thường (ví dụ: có hành lang)\n",
        "  - Tác nhân Ngẫu nhiên: Giống như trên, nó không quan tâm. Nó sẽ đi lang thang một cách ngẫu nhiên trong mọi không gian mà nó có thể vào được.\n",
        "  - Tác nhân Phản xạ Đơn giản: Tác nhân này xử lý tốt các hình dạng bất thường. Đối với nó, một hành lang chỉ là một không gian hẹp với các bức tường. Nó sẽ đi lang thang qua hành lang và vào các phòng khác một cách tự nhiên. Đây là ưu điểm lớn của việc không có một kế hoạch cứng nhắc.\n",
        "  - Tác nhân Dựa trên Mô hình: Sẽ thất bại hoàn toàn. Kế hoạch di chuyển \"cày ruộng\" của nó chỉ hoạt động trên một hình chữ nhật trống. Khi gặp một bức tường bất ngờ ở giữa (như ở góc của một phòng hình chữ L) hoặc một hành lang hẹp, logic di chuyển của nó sẽ bị phá vỡ. Nó không có khả năng tự tìm đường trong các không gian phức tạp.\n",
        "3. Nếu trong phòng có chướng ngại vật (đồ đạc)\n",
        "  - Tác nhân Ngẫu nhiên: Nó sẽ liên tục cố gắng di chuyển vào chướng ngại vật vì nó phớt lờ cảm biến va chạm. Điều này làm cho nó càng kém hiệu quả hơn.\n",
        "  - Tác nhân Phản xạ Đơn giản: Tác nhân này xem chướng ngại vật như những bức tường nhỏ. Nó sẽ va vào chúng, cảm nhận được, và thử một hướng đi khác. Nó có thể di chuyển xung quanh chướng ngại vật, nhưng cũng có thể bị kẹt trong một không gian hẹp giữa chướng ngại vật và tường.\n",
        "  - Tác nhân Dựa trên Mô hình: Sẽ thất bại hoàn toàn. Kế hoạch của nó yêu cầu các hàng di chuyển không bị cản trở. Một chướng ngại vật ở giữa đường đi sẽ làm hỏng toàn bộ lộ trình. Tác nhân không có logic để đi vòng qua một vật cản bất ngờ; nó sẽ coi đó là bức tường cuối phòng và làm sai lệch toàn bộ bản đồ nội bộ của nó.\n",
        "4. Nếu cảm biến bụi bẩn không hoàn hảo (sai 10%)\n",
        "  - Tác nhân Ngẫu nhiên: Không bị ảnh hưởng, vì nó vốn dĩ không sử dụng cảm biến này để ra quyết định.\n",
        "  - Tác nhân Phản xạ Đơn giản: Đây là một vấn đề lớn. Nếu cảm biến báo \"sạch\" ở một nơi \"bẩn\" (false negative), nó sẽ bỏ qua vết bẩn đó. Căn phòng có thể sẽ không bao giờ được dọn sạch hoàn toàn. Nếu cảm biến báo \"bẩn\" ở một nơi \"sạch\" (false positive), nó sẽ lãng phí một lượt để hút bụi một ô đã sạch. Điều này làm giảm hiệu suất.\n",
        "  - Tác nhân Dựa trên Mô hình: Tương tự như tác nhân phản xạ đơn giản. Lộ trình di chuyển của nó vẫn hoàn hảo, nhưng việc dọn dẹp sẽ không đáng tin cậy. Nó sẽ bỏ sót các vết bẩn (false negative) hoặc lãng phí năng lượng (false positive). Mục tiêu làm sạch hoàn toàn căn phòng sẽ không đạt được.\n",
        "5. Nếu cảm biến va chạm không hoàn hảo (không báo có tường 10%)\n",
        "  - Tác nhân Ngẫu nhiên: Không bị ảnh hưởng, vì nó phớt lờ cảm biến này.\n",
        "  - Tác nhân Phản xạ Đơn giản: Nó sẽ cố gắng di chuyển xuyên tường. Môi trường sẽ ngăn nó lại, nhưng nó đã lãng phí một hành động. Điều này làm giảm hiệu suất nhưng không làm hỏng hoàn toàn tác nhân.\n",
        "  - Tác nhân Dựa trên Mô hình: THẢM HỌA. Đây là trường hợp tệ nhất. Trong giai đoạn định vị, nếu nó không \"nhìn thấy\" bức tường phía tây hoặc phía bắc, nó sẽ không bao giờ biết mình đang ở góc và sẽ bị kẹt trong một vòng lặp vô tận. Trong giai đoạn dọn dẹp, nếu nó đến cuối một hàng và cảm biến không hoạt động, tọa độ nội bộ của nó sẽ bị cập nhật sai. Từ đó, toàn bộ bản đồ trong đầu của nó sẽ bị lệch so với thực tế và tác nhân sẽ hoàn toàn bị \"lạc\"."
      ],
      "metadata": {
        "id": "Jhy6bOeKJ9-1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_8XIkMnTwdT"
      },
      "source": [
        "## Advanced task: Imperfect Dirt Sensor\n",
        "\n",
        "* __Graduate students__ need to complete this task [10 points]\n",
        "* __Undergraduate students__ can attempt this as a bonus task [max +5 bonus points].\n",
        "\n",
        "1. Change your simulation environment to run experiments for the following problem: The dirt sensor has a 10% chance of giving the wrong reading. Perform experiments to observe how this changes the performance of the three implementations. Your model-based reflex agent is likely not able to clean the whole room, so you need to measure performance differently as a tradeoff between energy cost and number of uncleaned squares.\n",
        "\n",
        "2. Design an implement a solution for your model-based agent that will clean better. Show the improvement with experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LakZCb6zTwdT"
      },
      "outputs": [],
      "source": [
        "# Your code and discussion goes here\n",
        "import random\n",
        "\n",
        "class MôiTrường:\n",
        "    def __init__(self, kích_thước=(10, 10), độ_bẩn_ban_đầu=0.5):\n",
        "        self.kích_thước = kích_thước\n",
        "        self.grid = [[0] * kích_thước[1] for _ in range(kích_thước[0])]\n",
        "        self.vị_trí_tác_nhân = (0, 0)\n",
        "        self.năng_lượng = 0\n",
        "        self.tạo_bẩn(độ_bẩn_ban_đầu)\n",
        "\n",
        "    def tạo_bẩn(self, độ_bẩn):\n",
        "        for i in range(self.kích_thước[0]):\n",
        "            for j in range(self.kích_thước[1]):\n",
        "                if random.random() < độ_bẩn:\n",
        "                    self.grid[i][j] = 1 # 1 = bẩn, 0 = sạch\n",
        "\n",
        "    def cảm_nhận_bụi_bẩn(self, tỉ_lệ_sai=0.1):\n",
        "        x, y = self.vị_trí_tác_nhân\n",
        "        trạng_thái_thực = self.grid[x][y]\n",
        "        if random.random() < tỉ_lệ_sai:\n",
        "            return 1 - trạng_thái_thực # Trả về trạng thái sai\n",
        "        return trạng_thái_thực # Trả về trạng thái đúng\n",
        "\n",
        "    def di_chuyển_và_hút(self, hướng):\n",
        "        x, y = self.vị_trí_tác_nhân\n",
        "        năng_lượng_tiêu_thụ = 1\n",
        "\n",
        "        if hướng == \"hút\":\n",
        "            if self.grid[x][y] == 1:\n",
        "                self.grid[x][y] = 0\n",
        "                năng_lượng_tiêu_thụ += 10 # Chi phí hút bụi cao hơn\n",
        "        else: # Di chuyển\n",
        "            dx, dy = 0, 0\n",
        "            if hướng == \"lên\": dx = -1\n",
        "            elif hướng == \"xuống\": dx = 1\n",
        "            elif hướng == \"trái\": dy = -1\n",
        "            elif hướng == \"phải\": dy = 1\n",
        "\n",
        "            new_x, new_y = x + dx, y + dy\n",
        "            if 0 <= new_x < self.kích_thước[0] and 0 <= new_y < self.kích_thước[1]:\n",
        "                self.vị_trí_tác_nhân = (new_x, new_y)\n",
        "            else:\n",
        "                năng_lượng_tiêu_thụ += 5 # Chi phí va chạm tường\n",
        "\n",
        "        self.năng_lượng += năng_lượng_tiêu_thụ\n",
        "        return năng_lượng_tiêu_thụ\n",
        "\n",
        "    def đếm_ô_chưa_sạch(self):\n",
        "        chưa_sạch = sum(sum(row) for row in self.grid)\n",
        "        return chưa_sạch\n",
        "\n",
        "class TácNhân:\n",
        "    def __init__(self, môi_trường):\n",
        "        self.môi_trường = môi_trường\n",
        "\n",
        "    def hành_động(self, trạng_thái):\n",
        "        pass\n",
        "\n",
        "class TácNhânPhảnXạ(TácNhân):\n",
        "    def hành_động(self, trạng_thái):\n",
        "        if trạng_thái == 1:\n",
        "            return \"hút\"\n",
        "        return random.choice([\"lên\", \"xuống\", \"trái\", \"phải\"])\n",
        "\n",
        "class TácNhânDựaTrênMôHình(TácNhân):\n",
        "    def __init__(self, môi_trường):\n",
        "        super().__init__(môi_trường)\n",
        "        self.bản_đồ_nội_tâm = [[-1] * self.môi_trường.kích_thước[1] for _ in range(self.môi_trường.kích_thước[0])] # -1 = chưa khám phá, 0 = sạch, 1 = bẩn\n",
        "        self.vị_trí_đã_thăm = set()\n",
        "        self.lịch_sử_di_chuyển = []\n",
        "\n",
        "    def hành_động(self, trạng_thái):\n",
        "        x, y = self.môi_trường.vị_trí_tác_nhân\n",
        "        self.bản_đồ_nội_tâm[x][y] = trạng_thái\n",
        "        self.vị_trí_đã_thăm.add((x, y))\n",
        "\n",
        "        if trạng_thái == 1:\n",
        "            return \"hút\"\n",
        "\n",
        "        # Di chuyển tới ô chưa được khám phá\n",
        "        for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
        "            nx, ny = x + dx, y + dy\n",
        "            if 0 <= nx < self.môi_trường.kích_thước[0] and 0 <= ny < self.môi_trường.kích_thước[1] and self.bản_đồ_nội_tâm[nx][ny] == -1:\n",
        "                self.lịch_sử_di_chuyển.append((x, y))\n",
        "                if dx == 1: return \"xuống\"\n",
        "                if dx == -1: return \"lên\"\n",
        "                if dy == 1: return \"phải\"\n",
        "                if dy == -1: return \"trái\"\n",
        "\n",
        "        # Nếu đã khám phá hết, quay lại các ô bẩn (nếu có)\n",
        "        for i in range(self.môi_trường.kích_thước[0]):\n",
        "            for j in range(self.môi_trường.kích_thước[1]):\n",
        "                if self.bản_đồ_nội_tâm[i][j] == 1:\n",
        "                    # Logic di chuyển tới (i, j)\n",
        "                    pass\n",
        "\n",
        "        # Hoặc quay lại lịch sử di chuyển\n",
        "        if self.lịch_sử_di_chuyển:\n",
        "            self.lịch_sử_di_chuyển.pop()\n",
        "            # Logic di chuyển ngược lại\n",
        "\n",
        "        return random.choice([\"lên\", \"xuống\", \"trái\", \"phải\"])\n",
        "\n",
        "class TácNhânDựaTrênMôHìnhCảiTiến(TácNhânDựaTrênMôHình):\n",
        "    def hành_động(self, trạng_thái):\n",
        "        x, y = self.môi_trường.vị_trí_tác_nhân\n",
        "        self.bản_đồ_nội_tâm[x][y] = trạng_thái\n",
        "        self.vị_trí_đã_thăm.add((x, y))\n",
        "\n",
        "        # Cải tiến: Nếu cảm biến báo bẩn, hút ngay lập tức và ghi nhớ vị trí này\n",
        "        # Tránh việc di chuyển sang ô khác mà không hút, sau đó quay lại và có thể bỏ sót\n",
        "        if trạng_thái == 1:\n",
        "            return \"hút\"\n",
        "\n",
        "        # Tìm ô chưa được khám phá hoặc có thể là ô bẩn (dựa trên bản đồ nội tâm)\n",
        "        # Sử dụng thuật toán tìm đường đi đơn giản (BFS/DFS) hoặc chỉ đơn giản là đi theo thứ tự\n",
        "\n",
        "        # Chiến lược di chuyển theo một đường zig-zag để đảm bảo phủ hết diện tích\n",
        "        if (x, y) == (self.môi_trường.kích_thước[0] - 1, self.môi_trường.kích_thước[1] - 1):\n",
        "             return None # Kết thúc\n",
        "\n",
        "        if y % 2 == 0: # Di chuyển sang phải\n",
        "            if y < self.môi_trường.kích_thước[1] - 1:\n",
        "                return \"phải\"\n",
        "            else:\n",
        "                return \"xuống\"\n",
        "        else: # Di chuyển sang trái\n",
        "            if y > 0:\n",
        "                return \"trái\"\n",
        "            else:\n",
        "                return \"xuống\"\n",
        "\n",
        "class TácNhânMụcTiêu(TácNhân):\n",
        "    def __init__(self, môi_trường):\n",
        "        super().__init__(môi_trường)\n",
        "        self.mục_tiêu = []\n",
        "        for i in range(self.môi_trường.kích_thước[0]):\n",
        "            for j in range(self.môi_trường.kích_thước[1]):\n",
        "                if self.môi_trường.grid[i][j] == 1:\n",
        "                    self.mục_tiêu.append((i, j))\n",
        "\n",
        "    def hành_động(self, trạng_thái):\n",
        "        if self.mục_tiêu:\n",
        "            x, y = self.môi_trường.vị_trí_tác_nhân\n",
        "            mx, my = self.mục_tiêu[0]\n",
        "            if (x, y) == (mx, my):\n",
        "                self.mục_tiêu.pop(0)\n",
        "                return \"hút\"\n",
        "\n",
        "            # Di chuyển tới mục tiêu đầu tiên\n",
        "            if x < mx: return \"xuống\"\n",
        "            if x > mx: return \"lên\"\n",
        "            if y < my: return \"phải\"\n",
        "            if y > my: return \"trái\"\n",
        "\n",
        "        return None # Đã hoàn thành\n",
        "\n",
        "\n",
        "\n",
        "### Chạy các thử nghiệm\n",
        "\n",
        "\n",
        "def chạy_thử_nghiệm(tên_tác_nhân, tác_nhân, môi_trường, số_bước_tối_đa=200):\n",
        "    môi_trường_thử = MôiTrường(kích_thước=môi_trường.kích_thước, độ_bẩn_ban_đầu=0.5)\n",
        "    tác_nhân_thử = tác_nhân(môi_trường_thử)\n",
        "\n",
        "    for bước in range(số_bước_tối_đa):\n",
        "        trạng_thái_cảm_nhận = môi_trường_thử.cảm_nhận_bụi_bẩn(tỉ_lệ_sai=0.1)\n",
        "        hành_động = tác_nhân_thử.hành_động(trạng_thái_cảm_nhận)\n",
        "        if hành_động is None:\n",
        "            break\n",
        "        môi_trường_thử.di_chuyển_và_hút(hành_động)\n",
        "\n",
        "    chi_phí_năng_lượng = môi_trường_thử.năng_lượng\n",
        "    ô_chưa_sạch = môi_trường_thử.đếm_ô_chưa_sạch()\n",
        "\n",
        "    print(f\"--- Kết quả cho {tên_tác_nhân} ---\")\n",
        "    print(f\"Chi phí năng lượng: {chi_phí_năng_lượng}\")\n",
        "    print(f\"Số ô chưa sạch: {ô_chưa_sạch}\")\n",
        "    print(f\"Đánh đổi: {chi_phí_năng_lượng} + {ô_chưa_sạch*100} (giả định 1 ô chưa sạch = 100 năng lượng)\")\n",
        "    print(\"---------------------------------\")\n",
        "    return chi_phí_năng_lượng, ô_chưa_sạch\n",
        "\n",
        "def main():\n",
        "    môi_trường = MôiTrường()\n",
        "\n",
        "    print(\"Chạy thử nghiệm với cảm biến có 10% khả năng đưa ra kết quả sai\")\n",
        "\n",
        "    chạy_thử_nghiệm(\"Tác nhân phản xạ\", TácNhânPhảnXạ, môi_trường)\n",
        "    chạy_thử_nghiệm(\"Tác nhân dựa trên mô hình (cơ bản)\", TácNhânDựaTrênMôHình, môi_trường)\n",
        "    chạy_thử_nghiệm(\"Tác nhân mục tiêu\", TácNhânMụcTiêu, môi_trường)\n",
        "    chạy_thử_nghiệm(\"Tác nhân dựa trên mô hình (cải tiến)\", TácNhânDựaTrênMôHìnhCảiTiến, môi_trường)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D22Mz4uYTwdU"
      },
      "source": [
        "## More Advanced Implementation (not for credit)\n",
        "\n",
        "If the assignment was to easy for yuo then you can think about the following problems. These problems are challenging and not part of this assignment. We will learn implementation strategies and algorithms useful for these tasks during the rest of the semester.\n",
        "\n",
        "* __Obstacles:__ Change your simulation environment to run experiments for the following problem: Add random obstacle squares that also trigger the bumper sensor. The agent does not know where the obstacles are. Perform experiments to observe how this changes the performance of the three implementations. Describe what would need to be done to perform better with obstacles. Add code if you can.\n",
        "\n",
        "* __Agent for and environment with obstacles:__ Implement an agent for an environment where the agent does not know how large the environment is (we assume it is rectangular), where it starts or where the obstacles are. An option would be to always move to the closest unchecked/uncleaned square (note that this is actually depth-first search).\n",
        "\n",
        "* __Utility-based agent:__ Change the environment for a $5 \\times 5$ room, so each square has a fixed probability of getting dirty again. For the implementation, we give the environment a 2-dimensional array of probabilities. The utility of a state is defined as the number of currently clean squares in the room. Implement a utility-based agent that maximizes the expected utility over one full charge which lasts for 100000 time steps. To do this, the agent needs to learn the probabilities with which different squares get dirty again. This is very tricky!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mỗi lần chạy môi trường, thêm các ô ngẫu nhiên là obstacle.\n",
        "# Obstacle sẽ kích hoạt cảm biến bumper (như tường).\n",
        "# Agent không biết trước vị trí obstacle.\n",
        "# Cần quan sát hiệu năng của các agent đã code trước đó (simple reflex, model-based reflex, random, utility...).\n",
        "# Để cải thiện:\n",
        "# Agent nên lưu lại bản đồ để tránh đi vào obstacle nhiều lần.\n",
        "# Có thể áp dụng path planning (DFS/BFS/A*) khi muốn đến ô khác mà bị chặn.\n",
        "\n",
        "import random\n",
        "\n",
        "class EnvironmentWithObstacles:\n",
        "    def __init__(self, width, height, n_obstacles):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.grid = [['clean' for _ in range(width)] for _ in range(height)]\n",
        "        # Thêm chướng ngại vật\n",
        "        self.obstacles = set()\n",
        "        while len(self.obstacles) < n_obstacles:\n",
        "            x, y = random.randrange(width), random.randrange(height)\n",
        "            self.obstacles.add((x, y))\n",
        "\n",
        "    def is_obstacle(self, pos):\n",
        "        return pos in self.obstacles\n",
        "\n",
        "    def status(self, pos):\n",
        "        if self.is_obstacle(pos):\n",
        "            return 'obstacle'\n",
        "        return self.grid[pos[1]][pos[0]]\n",
        "\n",
        "    def dirty_random(self, prob=0.05):\n",
        "        for y in range(self.height):\n",
        "            for x in range(self.width):\n",
        "                if (x,y) not in self.obstacles and random.random() < prob:\n",
        "                    self.grid[y][x] = 'dirty'\n"
      ],
      "metadata": {
        "id": "Vvlf3nZhsS_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Môi trường không biết kích thước, không biết vị trí bắt đầu, và có obstacle.\n",
        "# Một chiến lược đơn giản:\n",
        "# Luôn di chuyển tới ô chưa thăm / chưa dọn gần nhất (giống DFS exploration).\n",
        "# Lưu bản đồ đã phát hiện vào một dict/map.\n",
        "# Tức là agent vừa khám phá, vừa dọn.\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "class ExploringAgent:\n",
        "    def __init__(self):\n",
        "        self.known_map = {}    # (x,y) -> \"clean\"/\"dirty\"/\"obstacle\"\n",
        "        self.visited = set()\n",
        "        self.frontier = set()\n",
        "        self.path = []         # danh sách các bước cần đi\n",
        "        self.pos = (0,0)\n",
        "\n",
        "    def neighbors(self, pos):\n",
        "        x, y = pos\n",
        "        return [(x+1,y), (x-1,y), (x,y+1), (x,y-1)]\n",
        "\n",
        "    def update_frontier(self):\n",
        "        for v in self.visited:\n",
        "            for n in self.neighbors(v):\n",
        "                if n not in self.visited and self.known_map.get(n) != \"obstacle\":\n",
        "                    self.frontier.add(n)\n",
        "\n",
        "    def bfs_path(self, start, goal):\n",
        "      queue = deque([(start, [])])\n",
        "      seen = {start}\n",
        "      while queue:\n",
        "        cur, path = queue.popleft()\n",
        "        if cur == goal:\n",
        "            return path\n",
        "        for n in self.neighbors(cur):\n",
        "            if n not in seen:\n",
        "                # Nếu chưa biết gì về ô n, vẫn cho phép đi qua (unknown = free)\n",
        "                if self.known_map.get(n) != \"obstacle\":\n",
        "                    seen.add(n)\n",
        "                    queue.append((n, path+[n]))\n",
        "      return None\n",
        "\n",
        "\n",
        "    def act(self, percept):\n",
        "        pos, dirty, bumper = percept\n",
        "        self.pos = pos\n",
        "\n",
        "        # Cập nhật bản đồ và visited\n",
        "        self.visited.add(pos)\n",
        "        self.known_map[pos] = \"dirty\" if dirty else \"clean\"\n",
        "\n",
        "        # Nếu ô này đang bẩn thì dọn trước\n",
        "        if dirty:\n",
        "            return \"suck\"\n",
        "\n",
        "        # Nếu có sẵn đường đi thì tiếp tục bước tiếp theo\n",
        "        if self.path:\n",
        "            next_step = self.path.pop(0)\n",
        "            dx, dy = next_step[0]-pos[0], next_step[1]-pos[1]\n",
        "            if dx == 1: return \"move_right\"\n",
        "            if dx == -1: return \"move_left\"\n",
        "            if dy == 1: return \"move_down\"\n",
        "            if dy == -1: return \"move_up\"\n",
        "\n",
        "        # Cập nhật frontier\n",
        "        self.update_frontier()\n",
        "\n",
        "        # Nếu còn frontier → chọn một mục tiêu và lập kế hoạch BFS\n",
        "        if self.frontier:\n",
        "            target = min(self.frontier, key=lambda f: abs(f[0]-pos[0])+abs(f[1]-pos[1]))\n",
        "            self.frontier.remove(target)\n",
        "            path = self.bfs_path(pos, target)\n",
        "            if path:\n",
        "                self.path = path\n",
        "                return self.act(percept)  # gọi lại để lấy action đầu tiên\n",
        "\n",
        "        # Nếu không còn gì để làm\n",
        "        return \"wait\"\n"
      ],
      "metadata": {
        "id": "FJPY6q3dsVCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mỗi ô (i,j) có probability p(i,j) để bẩn lại sau mỗi bước.\n",
        "\n",
        "# Utility của trạng thái = số ô sạch hiện tại.\n",
        "\n",
        "# Agent cần học ước lượng xác suất bẩn lại (thay vì biết trước).\n",
        "\n",
        "# Sau nhiều quan sát, agent có thể ước lượng xác suất bằng tần suất:\n",
        "\n",
        "#p^ (i, j) = (số lần ô (i,j) bẩn sau khi được dọn) / (số lần dọn ô (i,j))\n",
        "\n",
        "# Khi chọn hành động, agent chọn nước đi sao cho tối đa hóa kỳ vọng utility trong 100000 bước.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class ProbabilisticEnvironment:\n",
        "    def __init__(self, size=5):\n",
        "        self.size = size\n",
        "        # mỗi ô có xác suất riêng\n",
        "        self.probs = np.random.rand(size, size)\n",
        "        self.grid = np.zeros((size, size))  # 0 = clean, 1 = dirty\n",
        "\n",
        "    def step(self):\n",
        "        # mỗi bước: có thể bẩn lại\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if np.random.rand() < self.probs[i,j]:\n",
        "                    self.grid[i,j] = 1\n",
        "\n",
        "class UtilityAgent:\n",
        "    def __init__(self, size=5):\n",
        "        self.size = size\n",
        "        self.estimate = np.zeros((size,size))\n",
        "        self.clean_counts = np.zeros((size,size))\n",
        "        self.re_dirty_counts = np.zeros((size,size))\n",
        "\n",
        "    def update_estimate(self, pos, dirty_before, dirty_after):\n",
        "        i,j = pos\n",
        "        if dirty_before and not dirty_after:\n",
        "            self.clean_counts[i,j] += 1\n",
        "        if not dirty_before and dirty_after:\n",
        "            self.re_dirty_counts[i,j] += 1\n",
        "        # ước lượng\n",
        "        self.estimate[i,j] = self.re_dirty_counts[i,j] / max(1,self.clean_counts[i,j])\n",
        "\n",
        "    def act(self, pos, env):\n",
        "        i,j = pos\n",
        "        if env.grid[i,j] == 1:\n",
        "            env.grid[i,j] = 0\n",
        "            return 'suck'\n",
        "        # chọn ô bẩn có xác suất cao nhất để di chuyển tới\n",
        "        targets = np.argwhere(env.grid==1)\n",
        "        if len(targets)==0:\n",
        "            return 'wait'\n",
        "        target = targets[np.random.randint(len(targets))]\n",
        "        return f'move_to {tuple(target)}'\n"
      ],
      "metadata": {
        "id": "9UZEB9BksjrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code mô phỏng để test"
      ],
      "metadata": {
        "id": "F2x-wwWWxCXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class SimpleEnvironment:\n",
        "    def __init__(self, width=7, height=7, n_obstacles=5, dirt_prob=0.2, seed=42):\n",
        "        random.seed(seed)\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.agent_pos = (0, 0)\n",
        "        self.steps = 0\n",
        "\n",
        "        # Khởi tạo lưới: \"clean\" hoặc \"dirty\"\n",
        "        self.grid = {}\n",
        "        for x in range(width):\n",
        "            for y in range(height):\n",
        "                self.grid[(x, y)] = \"dirty\" if random.random() < dirt_prob else \"clean\"\n",
        "\n",
        "        # Thêm obstacles\n",
        "        self.obstacles = set()\n",
        "        while len(self.obstacles) < n_obstacles:\n",
        "            ox, oy = random.randrange(width), random.randrange(height)\n",
        "            if (ox, oy) != self.agent_pos:\n",
        "                self.obstacles.add((ox, oy))\n",
        "                self.grid[(ox, oy)] = \"obstacle\"\n",
        "\n",
        "    def sense(self):\n",
        "        \"\"\"Trả về percept cho agent\"\"\"\n",
        "        pos = self.agent_pos\n",
        "        dirty = self.grid.get(pos) == \"dirty\"\n",
        "        bumper = False  # cập nhật sau khi thử di chuyển\n",
        "        return (pos, dirty, bumper)\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Thực hiện action\"\"\"\n",
        "        x, y = self.agent_pos\n",
        "        bumper = False\n",
        "\n",
        "        if action == \"suck\":\n",
        "            if self.grid.get((x, y)) == \"dirty\":\n",
        "                self.grid[(x, y)] = \"clean\"\n",
        "                return (self.agent_pos, False, False), 10  # reward dọn sạch\n",
        "            return (self.agent_pos, False, False), -1\n",
        "\n",
        "        new_pos = None\n",
        "        if action == \"move_up\":\n",
        "            new_pos = (x, y - 1)\n",
        "        elif action == \"move_down\":\n",
        "            new_pos = (x, y + 1)\n",
        "        elif action == \"move_left\":\n",
        "            new_pos = (x - 1, y)\n",
        "        elif action == \"move_right\":\n",
        "            new_pos = (x + 1, y)\n",
        "\n",
        "        if new_pos:\n",
        "            if (0 <= new_pos[0] < self.width and\n",
        "                0 <= new_pos[1] < self.height and\n",
        "                new_pos not in self.obstacles):\n",
        "                self.agent_pos = new_pos\n",
        "            else:\n",
        "                bumper = True  # đụng obstacle hoặc tường\n",
        "\n",
        "        dirty = self.grid.get(self.agent_pos) == \"dirty\"\n",
        "        self.steps += 1\n",
        "        return (self.agent_pos, dirty, bumper), -0.1  # chi phí di chuyển nhẹ\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"In ra lưới\"\"\"\n",
        "        for y in range(self.height):\n",
        "            row = []\n",
        "            for x in range(self.width):\n",
        "                if (x, y) == self.agent_pos:\n",
        "                    row.append(\"A\")  # agent\n",
        "                elif (x, y) in self.obstacles:\n",
        "                    row.append(\"X\")  # obstacle\n",
        "                elif self.grid[(x, y)] == \"dirty\":\n",
        "                    row.append(\"*\")\n",
        "                else:\n",
        "                    row.append(\".\")\n",
        "            print(\" \".join(row))\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "LBpcPDXZw8S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_simulation(agent, env, max_steps=50):\n",
        "    for step in range(max_steps):\n",
        "        percept = env.sense()\n",
        "        action = agent.act(percept)\n",
        "        percept, reward = env.step(action)\n",
        "        env.render()\n",
        "        print(f\"Step {step}: Action={action}, Reward={reward}, Pos={env.agent_pos}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# Test\n",
        "env = SimpleEnvironment(width=7, height=7, n_obstacles=7, dirt_prob=0.3, seed=1)\n",
        "agent = ExploringAgent()\n",
        "\n",
        "run_simulation(agent, env, max_steps=30)\n"
      ],
      "metadata": {
        "id": "r1-dQ86ixPBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "toc-autonumbering": false,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}