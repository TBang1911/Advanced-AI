{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no7QnUkoGAfM"
      },
      "source": [
        "# Adversarial Search: Playing Connect 4\n",
        "\n",
        "Student Name: [Add your name]\n",
        "\n",
        "I have used the following AI tools: [list tools]\n",
        "\n",
        "I understand that my submission needs to be my own work: [your initials]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--15q0-AGAfW"
      },
      "source": [
        "## Learning Outcomes\n",
        "\n",
        "* Implement adversarial search algorithms for strategic game play.\n",
        "* Analyze and optimize search in complex game spaces.\n",
        "* Design effective heuristic evaluation functions.\n",
        "* Compare performance across different agent strategies.\n",
        "* Evaluate algorithmic trade-offs between decision quality and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ydv7KbcGAfY"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Total Points: Undergraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play Connect 4:\n",
        "\n",
        "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
        "\n",
        "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
        "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGfs3fUOGAfZ"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model (result function)\n",
        "* Goal state (terminal state and utility)\n",
        "\n",
        "Describe each component and then implement it as a function that can be used by search algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial State\n",
        "\n",
        "Bàn cờ Connect-4 là một lưới 6 hàng × 7 cột, ban đầu trống hoàn toàn.\n",
        "\n",
        "Người chơi đầu tiên thường được ký hiệu là 1 (hoặc 'X'), người chơi thứ hai là -1 (hoặc 'O').\n",
        "\n",
        "Actions\n",
        "\n",
        "Một hành động hợp lệ là đặt quân vào một cột chưa đầy (có ít nhất 1 ô trống ở cột đó).\n",
        "\n",
        "Mỗi hành động có thể biểu diễn bằng chỉ số cột col ∈ {0,…,6}.\n",
        "\n",
        "Transition Model (Result Function)\n",
        "\n",
        "Khi người chơi thực hiện hành động col, quân của họ rơi xuống ô trống thấp nhất trong cột đó.\n",
        "\n",
        "Sau khi cập nhật bàn cờ, lượt chơi được chuyển cho người chơi còn lại.\n",
        "\n",
        "Goal State (Terminal State and Utility)\n",
        "\n",
        "Trò chơi kết thúc khi:\n",
        "\n",
        "Một người chơi có 4 quân liên tiếp (ngang, dọc hoặc chéo) → người đó thắng.\n",
        "\n",
        "Hoặc bàn cờ đầy → hòa.\n",
        "\n",
        "Utility:\n",
        "\n",
        "+1 nếu người chơi hiện tại thắng,\n",
        "\n",
        "−1 nếu đối phương thắng,\n",
        "\n",
        "0 nếu hòa."
      ],
      "metadata": {
        "id": "xzUzCzxgOAy2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rg-nOLEzGAfa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "ROWS = 6\n",
        "COLS = 7\n",
        "\n",
        "# -------- INITIAL STATE --------\n",
        "def initial_state():\n",
        "    \"\"\"Trả về bàn cờ rỗng 6x7.\"\"\"\n",
        "    return np.zeros((ROWS, COLS), dtype=int)\n",
        "\n",
        "# -------- ACTIONS --------\n",
        "def actions(state):\n",
        "    \"\"\"Trả về danh sách các cột có thể thả quân.\"\"\"\n",
        "    return [c for c in range(COLS) if state[0][c] == 0]\n",
        "\n",
        "# -------- TRANSITION MODEL --------\n",
        "def result(state, action, player):\n",
        "    \"\"\"Trả về trạng thái mới sau khi người chơi `player` thả quân vào cột `action`.\"\"\"\n",
        "    new_state = state.copy()\n",
        "    for r in range(ROWS-1, -1, -1):\n",
        "        if new_state[r][action] == 0:\n",
        "            new_state[r][action] = player\n",
        "            break\n",
        "    return new_state\n",
        "\n",
        "# -------- TERMINAL STATE & UTILITY --------\n",
        "def check_winner(state):\n",
        "    \"\"\"Kiểm tra xem có ai thắng chưa.\"\"\"\n",
        "    # Kiểm tra hàng ngang\n",
        "    for r in range(ROWS):\n",
        "        for c in range(COLS - 3):\n",
        "            window = state[r, c:c+4]\n",
        "            if abs(sum(window)) == 4:\n",
        "                return np.sign(sum(window))\n",
        "    # Kiểm tra cột dọc\n",
        "    for c in range(COLS):\n",
        "        for r in range(ROWS - 3):\n",
        "            window = state[r:r+4, c]\n",
        "            if abs(sum(window)) == 4:\n",
        "                return np.sign(sum(window))\n",
        "    # Kiểm tra chéo chính /\n",
        "    for r in range(ROWS - 3):\n",
        "        for c in range(COLS - 3):\n",
        "            window = [state[r+i][c+i] for i in range(4)]\n",
        "            if abs(sum(window)) == 4:\n",
        "                return np.sign(sum(window))\n",
        "    # Kiểm tra chéo phụ \\\n",
        "    for r in range(3, ROWS):\n",
        "        for c in range(COLS - 3):\n",
        "            window = [state[r-i][c+i] for i in range(4)]\n",
        "            if abs(sum(window)) == 4:\n",
        "                return np.sign(sum(window))\n",
        "    return 0  # chưa có người thắng\n",
        "\n",
        "def terminal_test(state):\n",
        "    \"\"\"Kiểm tra xem bàn cờ có phải trạng thái kết thúc không.\"\"\"\n",
        "    return check_winner(state) != 0 or np.all(state != 0)\n",
        "\n",
        "def utility(state):\n",
        "    \"\"\"Tính utility của trạng thái cuối.\"\"\"\n",
        "    winner = check_winner(state)\n",
        "    if winner == 1:\n",
        "        return 1\n",
        "    elif winner == -1:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyWgHmTNGAfc"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích:\n",
        "\n",
        "Mỗi ô có thể có 3 trạng thái: {trống, người chơi 1, người chơi 2}\n",
        "→ Tổng số cấu hình tối đa:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Tuy nhiên, nhiều trạng thái là không hợp lệ (ví dụ, số quân chênh lệch quá lớn).\n",
        "→ Số trạng thái hợp lệ thực tế được ước lượng khoảng ~4.5 × 10¹² (theo các nghiên cứu về Connect-4).\n",
        "\n",
        "→ Ước lượng không gian trạng thái hợp lệ: khoảng 10¹³."
      ],
      "metadata": {
        "id": "-f6XS8EBORhs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAOptwKAGAfd"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích:\n",
        "\n",
        "Ở mỗi lượt có tối đa 7 hành động hợp lệ.\n",
        "\n",
        "Trò chơi có tối đa 42 lượt (6 × 7 ô).\n",
        "→ Số nút trong cây trò chơi đầy đủ (ước lượng cực đại):\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Tuy nhiên, thực tế ít hơn nhiều vì:\n",
        "\n",
        "Một số nhánh kết thúc sớm do thắng hoặc hòa.\n",
        "\n",
        "\n",
        "Không phải tất cả 7 cột đều hợp lệ mỗi bước.\n",
        "\n",
        "→ Ước lượng thực tế: khoảng 10²⁵ – 10³⁰ nút."
      ],
      "metadata": {
        "id": "CjdUHWtoOdNs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkyvQt-GAfe"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [25 point]\n",
        "\n",
        "Use a numpy character array as the board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uCj_FWlRGAfe",
        "outputId": "086dd2f5-47bf-40b8-f518-b6a32aa3d82a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def empty_board(shape=(6, 7)):\n",
        "    return np.full(shape=shape, fill_value=0)\n",
        "\n",
        "print(empty_board())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGmtuOyDGAfg"
      },
      "source": [
        "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "p2aU8gSsGAfg",
        "outputId": "7f51f401-7b91-4f48-8e7e-3490cd878ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualization code by Randolph Rankin\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize(board):\n",
        "    plt.axes()\n",
        "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
        "    circles=[]\n",
        "    for i,row in enumerate(board):\n",
        "        for j,val in enumerate(row):\n",
        "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
        "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
        "\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    for circle in circles:\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n",
        "board = [[0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0,-1,-1, 1,-1, 0, 0]]\n",
        "visualize(board)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "DeiQakEuGAfh"
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* A check for available actions in each state `actions(state)`.\n",
        "* The transition model `result(state, player, action)`.\n",
        "* Check for terminal states `terminal(state)`.\n",
        "* The utility function `utility(state, player)`.\n",
        "\n",
        "The player argument is used so your agent can play red or yellow.\n",
        "Make sure that all these functions work with boards of different sizes (number of columns and rows).\n",
        "You can follow the [tic-tac-toe example from class.](https://colab.research.google.com/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_definitions.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SazR1M-9GAfh"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Tạo board trống\n",
        "def empty_board(shape=(6,7)):\n",
        "    return np.zeros(shape, dtype=int)\n",
        "\n",
        "# 1. Các hành động hợp lệ (những cột còn chỗ trống)\n",
        "def actions(board):\n",
        "    valid_cols = []\n",
        "    for col in range(board.shape[1]):\n",
        "        if board[0, col] == 0:\n",
        "            valid_cols.append(col)\n",
        "    return valid_cols\n",
        "\n",
        "# 2. Thực hiện một hành động → tạo ra trạng thái mới\n",
        "def result(board, player, action):\n",
        "    new_board = board.copy()\n",
        "    for row in reversed(range(board.shape[0])):\n",
        "        if new_board[row, action] == 0:\n",
        "            new_board[row, action] = player\n",
        "            return new_board\n",
        "    return new_board  # fallback\n",
        "\n",
        "# 3. Kiểm tra trạng thái kết thúc\n",
        "def terminal(board):\n",
        "    rows, cols = board.shape\n",
        "    # Kiểm tra thắng\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if board[r,c] != 0:\n",
        "                p = board[r,c]\n",
        "                # Ngang\n",
        "                if c+3 < cols and all(board[r,c+i] == p for i in range(4)):\n",
        "                    return True\n",
        "                # Dọc\n",
        "                if r+3 < rows and all(board[r+i,c] == p for i in range(4)):\n",
        "                    return True\n",
        "                # Chéo xuống phải\n",
        "                if r+3 < rows and c+3 < cols and all(board[r+i,c+i] == p for i in range(4)):\n",
        "                    return True\n",
        "                # Chéo xuống trái\n",
        "                if r+3 < rows and c-3 >= 0 and all(board[r+i,c-i] == p for i in range(4)):\n",
        "                    return True\n",
        "\n",
        "    # Full board → hòa\n",
        "    if len(actions(board)) == 0:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# 4. Utility đánh giá trạng thái khi terminal\n",
        "def utility(board, player):\n",
        "    rows, cols = board.shape\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if board[r,c] != 0:\n",
        "                p = board[r,c]\n",
        "                # Ngang\n",
        "                if c+3 < cols and all(board[r,c+i] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "                # Dọc\n",
        "                if r+3 < rows and all(board[r+i,c] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "                # Chéo xuống phải\n",
        "                if r+3 < rows and c+3 < cols and all(board[r+i,c+i] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "                # Chéo xuống trái\n",
        "                if r+3 < rows and c-3 >= 0 and all(board[r+i,c-i] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "    return 0  # hòa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDh9-NrGAfh"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = 1): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-9EVR3LRGAfi"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "def random_player(board, player=1):\n",
        "    valid_moves = actions(board)\n",
        "    return random.choice(valid_moves)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gQZM31GAfi"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Hh17XUMgol2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "id": "wdsWAsgeGAfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57d7cf6-5f9c-4018-8a09-046d7ed0f58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KẾT QUẢ SAU 1000 GAME:\n",
            "Player 1 thắng: 585\n",
            "Player 2 thắng: 414\n",
            "Hòa: 1\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "def play_game():\n",
        "    board = empty_board()\n",
        "    player = 1\n",
        "    while not terminal(board):\n",
        "        action = random_player(board, player)\n",
        "        board = result(board, player, action)\n",
        "        player *= -1  # đổi lượt\n",
        "    return utility(board, 1)\n",
        "\n",
        "# Thống kê kết quả\n",
        "num_games = 1000\n",
        "results = [play_game() for _ in range(num_games)]\n",
        "\n",
        "player1_wins = results.count(1)\n",
        "player2_wins = results.count(-1)\n",
        "draws = results.count(0)\n",
        "\n",
        "print(\"KẾT QUẢ SAU 1000 GAME:\")\n",
        "print(\"Player 1 thắng:\", player1_wins)\n",
        "print(\"Player 2 thắng:\", player2_wins)\n",
        "print(\"Hòa:\", draws)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl-ChzAxGAfi"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
        "\n",
        "### Implement the Search [20 points]\n",
        "\n",
        "Implement minimax search starting from a given board for specifying the player.\n",
        "\n",
        "__Important Notes:__\n",
        "* You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
        "This is essential to be able play against agents from other students later.\n",
        "* The game tree for a $6 \\times 7$ board is huge and optimal algorithms need to visit each or a large percentage of all nodes in the tree. You can experiment with smaller boards like a $4 \\times 4$ board first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FpmvlPVHGAfj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def empty_board(rows=6, cols=7):\n",
        "    return np.zeros((rows, cols), dtype=int)\n",
        "\n",
        "def actions(board):\n",
        "    return [c for c in range(board.shape[1]) if board[0, c] == 0]\n",
        "\n",
        "def result(board, player, action):\n",
        "    b = board.copy()\n",
        "    rows = b.shape[0]\n",
        "    # Tìm hàng thấp nhất còn trống trong cột đã chọn\n",
        "    for r in range(rows - 1, -1, -1):\n",
        "        if b[r, action] == 0:\n",
        "            b[r, action] = player\n",
        "            return b\n",
        "    raise ValueError(f\"Cột {action} đã đầy.\")\n",
        "\n",
        "def check_winner(board, k=4):\n",
        "    rows, cols = board.shape\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            player = board[r, c]\n",
        "            if player == 0:\n",
        "                continue\n",
        "\n",
        "            # Kiểm tra hàng ngang\n",
        "            if c + k <= cols and np.all(board[r, c:c+k] == player):\n",
        "                return player\n",
        "            # Kiểm tra hàng dọc\n",
        "            if r + k <= rows and np.all(board[r:r+k, c] == player):\n",
        "                return player\n",
        "            # Kiểm tra đường chéo chính (top-left to bottom-right)\n",
        "            if r + k <= rows and c + k <= cols and np.all([board[r+i, c+i] for i in range(k)] == player):\n",
        "                return player\n",
        "            # Kiểm tra đường chéo phụ (bottom-left to top-right)\n",
        "            if r - k + 1 >= 0 and c + k <= cols and np.all([board[r-i, c+i] for i in range(k)] == player):\n",
        "                return player\n",
        "    return 0\n",
        "\n",
        "def terminal(board, k=4):\n",
        "    winner = check_winner(board, k)\n",
        "    if winner != 0:\n",
        "        return True, winner\n",
        "    if not actions(board): # Bàn cờ đầy\n",
        "        return True, 0\n",
        "    return False, 0\n",
        "\n",
        "def utility(board, player, k=4):\n",
        "    is_terminal, winner = terminal(board, k)\n",
        "    if not is_terminal:\n",
        "        return 0\n",
        "    if winner == player:\n",
        "        return 1\n",
        "    if winner == -player:\n",
        "        return -1\n",
        "    return 0\n",
        "\n",
        "class MinimaxAgent:\n",
        "    def __init__(self, player=1):\n",
        "        self.player = player\n",
        "        self.nodes_visited = 0\n",
        "\n",
        "    def get_action(self, board, player=1):\n",
        "        self.player = player\n",
        "        self.nodes_visited = 0\n",
        "\n",
        "        _, action = self.max_value(board, -math.inf, math.inf)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def max_value(self, board, alpha, beta):\n",
        "        self.nodes_visited += 1\n",
        "        is_terminal, _ = terminal(board)\n",
        "        if is_terminal:\n",
        "            return utility(board, self.player), None\n",
        "\n",
        "        v = -math.inf\n",
        "        move = None\n",
        "        for a in actions(board):\n",
        "            new_board = result(board, self.player, a)\n",
        "            v2, _ = self.min_value(new_board, alpha, beta)\n",
        "            if v2 > v:\n",
        "                v = v2\n",
        "                move = a\n",
        "                alpha = max(alpha, v)\n",
        "            if v >= beta:\n",
        "                return v, move\n",
        "        return v, move\n",
        "\n",
        "    def min_value(self, board, alpha, beta):\n",
        "        self.nodes_visited += 1\n",
        "        is_terminal, _ = terminal(board)\n",
        "        if is_terminal:\n",
        "            return utility(board, self.player), None\n",
        "\n",
        "        v = math.inf\n",
        "        move = None\n",
        "        # Đối thủ của self.player là -self.player\n",
        "        opponent = -self.player\n",
        "        for a in actions(board):\n",
        "            new_board = result(board, opponent, a)\n",
        "            v2, _ = self.max_value(new_board, alpha, beta)\n",
        "            if v2 < v:\n",
        "                v = v2\n",
        "                move = a\n",
        "                beta = min(beta, v)\n",
        "            if v <= alpha:\n",
        "                return v, move\n",
        "        return v, move\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrVOvXW6GAfj"
      },
      "source": [
        "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YsaqoNNeGAfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754c7c97-f494-4b44-adb4-be4de19a0501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Board 1 (Win Horizontally) ---\n",
            "Board state:\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [1 1 1 0]]\n",
            "Agent (Player 1) chose column: 2\n",
            "\n",
            "--- Testing Board 2 (Block Vertically) ---\n",
            "Board state:\n",
            "[[ 0  0  0  0]\n",
            " [ 0 -1  0  0]\n",
            " [ 0 -1  1  0]\n",
            " [ 1 -1  1  0]]\n",
            "Agent (Player 1) chose column: 1\n",
            "\n",
            "--- Testing Board 3 (Block Diagonally) ---\n",
            "Board state:\n",
            "[[ 0  0  0  0]\n",
            " [ 0  0  0 -1]\n",
            " [ 0  1 -1  0]\n",
            " [ 1 -1  1  1]]\n",
            "Agent (Player 1) chose column: 2\n",
            "\n",
            "--- Testing Board 4 (Setup a fork) ---\n",
            "Board state:\n",
            "[[ 0  0  0  0]\n",
            " [ 0  0  0  0]\n",
            " [ 0 -1  0  0]\n",
            " [ 1  1 -1  0]]\n",
            "Agent (Player 1) chose column: 0\n",
            "\n",
            "--- Testing Board 5 (Complex middle game) ---\n",
            "Board state:\n",
            "[[ 0  0  0  0]\n",
            " [ 0  1  0  0]\n",
            " [-1 -1  1  0]\n",
            " [ 1  1 -1 -1]]\n",
            "Agent (Player 1) chose column: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Cơ hội thắng ngay lập tức theo chiều ngang\n",
        "board1 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [1, 1, 1, 0]\n",
        "])\n",
        "\n",
        "# 2. Phải chặn đối thủ thắng theo chiều dọc\n",
        "board2 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0,-1, 0, 0],\n",
        "    [0,-1, 1, 0],\n",
        "    [1,-1, 1, 0]\n",
        "])\n",
        "\n",
        "# 3. Phải chặn đối thủ thắng theo đường chéo\n",
        "board3 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0,-1],\n",
        "    [0, 1,-1, 0],\n",
        "    [1,-1, 1, 1]\n",
        "])\n",
        "\n",
        "# 4. Tạo ra một bẫy (fork)\n",
        "board4 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [0,-1, 0, 0],\n",
        "    [1, 1,-1, 0]\n",
        "])\n",
        "\n",
        "\n",
        "# 5. Một tình huống phức tạp hơn ở giữa game\n",
        "board5 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [-1,-1, 1, 0],\n",
        "    [1, 1,-1,-1]\n",
        "])\n",
        "\n",
        "test_boards = {\n",
        "    \"Board 1 (Win Horizontally)\": board1,\n",
        "    \"Board 2 (Block Vertically)\": board2,\n",
        "    \"Board 3 (Block Diagonally)\": board3,\n",
        "    \"Board 4 (Setup a fork)\": board4,\n",
        "    \"Board 5 (Complex middle game)\": board5\n",
        "}\n",
        "\n",
        "# Khởi tạo agent\n",
        "minimax_agent = MinimaxAgent()\n",
        "\n",
        "# Chạy thử nghiệm\n",
        "for name, board in test_boards.items():\n",
        "    print(f\"--- Testing {name} ---\")\n",
        "    print(\"Board state:\")\n",
        "    print(board)\n",
        "\n",
        "    # Player 1's turn\n",
        "    best_move = minimax_agent.get_action(board, player=1)\n",
        "\n",
        "    print(f\"Agent (Player 1) chose column: {best_move}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT7t-XTvGAfj"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns/rows. Explain why using this algorithm on a standard $6 \\times 7$ board is not feasible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mdRJmGWpGAfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "b3b80063-a07c-41d3-ecc6-e07b3743e730"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating first move for a 4x4 board...\n",
            "Time taken: 11.9103 seconds\n",
            "\n",
            "Calculating first move for a 4x5 board...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-929140435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, board, player)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes_visited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, board, alpha, beta)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mis_terminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_terminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mutility\u001b[0;34m(board, player, k)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mis_terminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_terminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mterminal\u001b[0;34m(board, k)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1033545242.py\u001b[0m in \u001b[0;36mcheck_winner\u001b[0;34m(board, k)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Kiểm tra đường chéo phụ (bottom-left to top-right)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \"\"\"\n\u001b[0;32m-> 2601\u001b[0;31m     return _wrapreduction_any_all(a, np.logical_and, 'all', axis, out,\n\u001b[0m\u001b[1;32m   2602\u001b[0m                                   keepdims=keepdims, where=where)\n\u001b[1;32m   2603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction_any_all\u001b[0;34m(obj, ufunc, method, axis, out, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "board_sizes = [\n",
        "    (4, 4),\n",
        "    (4, 5),\n",
        "    (5, 5),\n",
        "    (5, 6),\n",
        "]\n",
        "\n",
        "timing_results = {}\n",
        "agent = MinimaxAgent()\n",
        "\n",
        "for rows, cols in board_sizes:\n",
        "    board = empty_board(rows=rows, cols=cols)\n",
        "    print(f\"Calculating first move for a {rows}x{cols} board...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    agent.get_action(board, player=1)\n",
        "    end_time = time.time()\n",
        "\n",
        "    duration = end_time - start_time\n",
        "    timing_results[f\"{rows}x{cols}\"] = duration\n",
        "    print(f\"Time taken: {duration:.4f} seconds\\n\")\n",
        "\n",
        "print(\"--- Timing Results Summary ---\")\n",
        "for size, t in timing_results.items():\n",
        "    print(f\"Board {size}: {t:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7li2T9jGAfj"
      },
      "source": [
        "### Move ordering [5 points]\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q6ZeVd4EGAfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "c3c89742-edd4-4de1-9c4f-f2e49218d75e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Strategy  Average Time (s)\n",
              "0    No Move Ordering             0.037\n",
              "1  With Move Ordering             0.016"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cddacc92-0aa5-4ac0-99b8-aa142b00f8b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Strategy</th>\n",
              "      <th>Average Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Move Ordering</td>\n",
              "      <td>0.037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>With Move Ordering</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cddacc92-0aa5-4ac0-99b8-aa142b00f8b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cddacc92-0aa5-4ac0-99b8-aa142b00f8b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cddacc92-0aa5-4ac0-99b8-aa142b00f8b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-66713bb6-b896-43ad-8f64-fd681ad07d51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66713bb6-b896-43ad-8f64-fd681ad07d51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-66713bb6-b896-43ad-8f64-fd681ad07d51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"With Move Ordering\",\n          \"No Move Ordering\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014849242404917497,\n        \"min\": 0.016,\n        \"max\": 0.037,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.016,\n          0.037\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "class Connect4Game:\n",
        "    def __init__(self, rows=6, cols=7):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.board = np.zeros((rows, cols), dtype=int)\n",
        "\n",
        "    def copy(self):\n",
        "        new_game = Connect4Game(self.rows, self.cols)\n",
        "        new_game.board = np.copy(self.board)\n",
        "        return new_game\n",
        "\n",
        "    def available_actions(self):\n",
        "        \"\"\"Trả về danh sách cột có thể thả quân.\"\"\"\n",
        "        return [c for c in range(self.cols) if self.board[0][c] == 0]\n",
        "\n",
        "    def make_move(self, col, player):\n",
        "        \"\"\"Thả quân vào cột và cập nhật bàn cờ.\"\"\"\n",
        "        for r in range(self.rows-1, -1, -1):\n",
        "            if self.board[r][col] == 0:\n",
        "                self.board[r][col] = player\n",
        "                break\n",
        "\n",
        "    def is_full(self):\n",
        "        return np.all(self.board != 0)\n",
        "\n",
        "    def check_winner(self):\n",
        "        \"\"\"Kiểm tra người thắng.\"\"\"\n",
        "        board = self.board\n",
        "        for r in range(self.rows):\n",
        "            for c in range(self.cols - 3):\n",
        "                if abs(sum(board[r, c:c+4])) == 4:\n",
        "                    return np.sign(sum(board[r, c:c+4]))\n",
        "        for c in range(self.cols):\n",
        "            for r in range(self.rows - 3):\n",
        "                if abs(sum(board[r:r+4, c])) == 4:\n",
        "                    return np.sign(sum(board[r:r+4, c]))\n",
        "        for r in range(self.rows - 3):\n",
        "            for c in range(self.cols - 3):\n",
        "                if abs(sum([board[r+i][c+i] for i in range(4)])) == 4:\n",
        "                    return np.sign(sum([board[r+i][c+i] for i in range(4)]))\n",
        "        for r in range(3, self.rows):\n",
        "            for c in range(self.cols - 3):\n",
        "                if abs(sum([board[r-i][c+i] for i in range(4)])) == 4:\n",
        "                    return np.sign(sum([board[r-i][c+i] for i in range(4)]))\n",
        "        return 0\n",
        "\n",
        "    def is_terminal(self):\n",
        "        \"\"\"Kiểm tra trạng thái kết thúc.\"\"\"\n",
        "        return self.check_winner() != 0 or self.is_full()\n",
        "\n",
        "class MinimaxAgent:\n",
        "    def __init__(self, depth=4):\n",
        "        self.depth = depth\n",
        "\n",
        "    def evaluate(self, game):\n",
        "        \"\"\"Hàm heuristic đơn giản: tính điểm dựa trên số quân 2-3 liên tiếp.\"\"\"\n",
        "        board = game.board\n",
        "        score = 0\n",
        "        player = 1\n",
        "        opponent = -1\n",
        "\n",
        "        # Ưu tiên trung tâm\n",
        "        center_array = [int(i) for i in list(board[:, game.cols//2])]\n",
        "        score += center_array.count(player) * 3\n",
        "\n",
        "        # Cộng/trừ điểm theo số quân liên tiếp\n",
        "        def score_window(window):\n",
        "            nonlocal score\n",
        "            if window.count(player) == 4:\n",
        "                score += 100\n",
        "            elif window.count(player) == 3 and window.count(0) == 1:\n",
        "                score += 5\n",
        "            elif window.count(player) == 2 and window.count(0) == 2:\n",
        "                score += 2\n",
        "            if window.count(opponent) == 3 and window.count(0) == 1:\n",
        "                score -= 4\n",
        "\n",
        "        # Quét theo hàng\n",
        "        for r in range(game.rows):\n",
        "            row_array = [int(i) for i in list(board[r,:])]\n",
        "            for c in range(game.cols - 3):\n",
        "                window = row_array[c:c+4]\n",
        "                score_window(window)\n",
        "        # Quét theo cột\n",
        "        for c in range(game.cols):\n",
        "            col_array = [int(i) for i in list(board[:,c])]\n",
        "            for r in range(game.rows - 3):\n",
        "                window = col_array[r:r+4]\n",
        "                score_window(window)\n",
        "        # Quét chéo /\n",
        "        for r in range(game.rows - 3):\n",
        "            for c in range(game.cols - 3):\n",
        "                window = [board[r+i][c+i] for i in range(4)]\n",
        "                score_window(window)\n",
        "        # Quét chéo \\\n",
        "        for r in range(game.rows - 3):\n",
        "            for c in range(game.cols - 3):\n",
        "                window = [board[r+3-i][c+i] for i in range(4)]\n",
        "                score_window(window)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def minimax(self, game, depth, alpha, beta, maximizingPlayer):\n",
        "        if depth == 0 or game.is_terminal():\n",
        "            return self.evaluate(game)\n",
        "\n",
        "        valid_moves = game.available_actions()\n",
        "\n",
        "        if maximizingPlayer:\n",
        "            value = -math.inf\n",
        "            for col in valid_moves:\n",
        "                new_game = game.copy()\n",
        "                new_game.make_move(col, 1)\n",
        "                value = max(value, self.minimax(new_game, depth-1, alpha, beta, False))\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "        else:\n",
        "            value = math.inf\n",
        "            for col in valid_moves:\n",
        "                new_game = game.copy()\n",
        "                new_game.make_move(col, -1)\n",
        "                value = min(value, self.minimax(new_game, depth-1, alpha, beta, True))\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "    def get_action(self, game):\n",
        "        \"\"\"Trả về cột tốt nhất để đánh.\"\"\"\n",
        "        valid_moves = game.available_actions()\n",
        "        best_score = -math.inf\n",
        "        best_col = np.random.choice(valid_moves)\n",
        "        for col in valid_moves:\n",
        "            new_game = game.copy()\n",
        "            new_game.make_move(col, 1)\n",
        "            score = self.minimax(new_game, self.depth-1, -math.inf, math.inf, False)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_col = col\n",
        "        return best_col\n",
        "\n",
        "def ordered_moves(moves, cols):\n",
        "    \"\"\"Ưu tiên các cột giữa.\"\"\"\n",
        "    center = cols // 2\n",
        "    return sorted(moves, key=lambda x: abs(center - x))\n",
        "\n",
        "# Test time comparison between random and ordered moves\n",
        "game = Connect4Game(rows=4, cols=4)\n",
        "agent = MinimaxAgent(depth=4)\n",
        "\n",
        "def test_move_ordering(ordering=True):\n",
        "    start = time.time()\n",
        "    valid_moves = game.available_actions()\n",
        "    if ordering:\n",
        "        valid_moves = ordered_moves(valid_moves, game.cols)\n",
        "    for col in valid_moves:\n",
        "        new_game = game.copy()\n",
        "        new_game.make_move(col, 1)\n",
        "        _ = agent.minimax(new_game, 3, -math.inf, math.inf, False)\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "t1 = test_move_ordering(ordering=False)\n",
        "t2 = test_move_ordering(ordering=True)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame({\n",
        "    \"Strategy\": [\"No Move Ordering\", \"With Move Ordering\"],\n",
        "    \"Average Time (s)\": [round(t1, 3), round(t2, 3)]\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPyqN_sxGAfk"
      },
      "source": [
        "### The first few moves [5 points]\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nYURdxPoGAfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f771d7-cc48-4ee8-a58b-b322d1cfbd07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action được chọn bởi Minimax: 0\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "# ==== Helper Functions (tái sử dụng từ Task 2) ====\n",
        "\n",
        "def actions(board):\n",
        "    return [c for c in range(board.shape[1]) if board[0, c] == 0]\n",
        "\n",
        "def result(board, player, action):\n",
        "    new_board = board.copy()\n",
        "    for row in reversed(range(board.shape[0])):\n",
        "        if new_board[row, action] == 0:\n",
        "            new_board[row, action] = player\n",
        "            return new_board\n",
        "    return new_board\n",
        "\n",
        "def terminal(board):\n",
        "    # kiếm tra thắng\n",
        "    rows, cols = board.shape\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if board[r,c] != 0:\n",
        "                p = board[r,c]\n",
        "                # ngang\n",
        "                if c+3 < cols and all(board[r,c+i] == p for i in range(4)):\n",
        "                    return True\n",
        "                # dọc\n",
        "                if r+3 < rows and all(board[r+i,c] == p for i in range(4)):\n",
        "                    return True\n",
        "                # chéo phải\n",
        "                if r+3 < rows and c+3 < cols and all(board[r+i,c+i] == p for i in range(4)):\n",
        "                    return True\n",
        "                # chéo trái\n",
        "                if r+3 < rows and c-3 >= 0 and all(board[r+i,c-i] == p for i in range(4)):\n",
        "                    return True\n",
        "    return len(actions(board)) == 0  # Hòa\n",
        "\n",
        "def utility(board, player):\n",
        "    rows, cols = board.shape\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if board[r,c] != 0:\n",
        "                p = board[r,c]\n",
        "                if c+3 < cols and all(board[r,c+i] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "                if r+3 < rows and all(board[r+i,c] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "                if r+3 < rows and c+3 < cols and all(board[r+i,c+i] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "                if r+3 < rows and c-3 >= 0 and all(board[r+i,c-i] == p for i in range(4)):\n",
        "                    return 1 if p == player else -1\n",
        "    return 0\n",
        "\n",
        "# ==== Heuristic Eval (giới hạn độ sâu) ====\n",
        "def heuristic(board, player):\n",
        "    return random.randint(-5, 5)  # đơn giản để minh hoạ\n",
        "\n",
        "\n",
        "# ==== Minimax với Alpha-Beta Pruning ====\n",
        "def minimax(board, player, depth, alpha, beta, max_player):\n",
        "    if terminal(board):\n",
        "        return utility(board, max_player)\n",
        "    if depth == 0:\n",
        "        return heuristic(board, max_player)\n",
        "\n",
        "    if player == max_player:  # Maximizing\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            value = max(value,\n",
        "                        minimax(result(board, player, action),\n",
        "                                -player,\n",
        "                                depth-1,\n",
        "                                alpha, beta,\n",
        "                                max_player))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:  # Minimizing\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            value = min(value,\n",
        "                        minimax(result(board, player, action),\n",
        "                                -player,\n",
        "                                depth-1,\n",
        "                                alpha, beta,\n",
        "                                max_player))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "\n",
        "\n",
        "# ==== Agent sử dụng Minimax ====\n",
        "def minimax_player(board, player=1, depth=4):\n",
        "    best_value = -math.inf\n",
        "    best_action = random.choice(actions(board))  # fallback\n",
        "\n",
        "    for action in actions(board):\n",
        "        value = minimax(result(board, player, action),\n",
        "                        -player,\n",
        "                        depth-1,\n",
        "                        -math.inf, math.inf,\n",
        "                        player)\n",
        "        if value > best_value:\n",
        "            best_value = value\n",
        "            best_action = action\n",
        "    return best_action\n",
        "\n",
        "\n",
        "# ==== TEST chạy nước đầu tiên trên bàn cờ rỗng ====\n",
        "board = np.zeros((6,7), dtype=int)\n",
        "action = minimax_player(board, player=1, depth=4)\n",
        "print(\"Action được chọn bởi Minimax:\", action)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCVuMA1kGAfk"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a $4 \\times 4$ board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8uwCjUpOGAfk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "289a28f1-f97f-4ba5-c65e-f255f05d596b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating 1000 games on a 4x4 board...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MinimaxAgent.get_action() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2347548983.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Minimax đi trước\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimax_player\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwins_minimax\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2347548983.py\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(agent1, agent2, rows, cols)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Lấy nước đi từ agent hiện tại\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_player_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2347548983.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(board, player)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mminimax_agent_4x4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinimaxAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Định nghĩa lại agent để có signature phù hợp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mminimax_player\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminimax_agent_4x4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MinimaxAgent.get_action() takes 2 positional arguments but 3 were given"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def random_player(board, player=1):\n",
        "    possible_actions = actions(board)\n",
        "    return random.choice(possible_actions)\n",
        "\n",
        "def play_game(agent1, agent2, rows=4, cols=4):\n",
        "    board = empty_board(rows, cols)\n",
        "    current_player_agent = agent1\n",
        "    player_id = 1\n",
        "\n",
        "    while True:\n",
        "        # Lấy nước đi từ agent hiện tại\n",
        "        move = current_player_agent(board, player_id)\n",
        "        board = result(board, player_id, move)\n",
        "\n",
        "        # Kiểm tra kết thúc\n",
        "        is_terminal, winner = terminal(board)\n",
        "        if is_terminal:\n",
        "            return winner\n",
        "\n",
        "        # Đổi lượt\n",
        "        player_id = -player_id\n",
        "        current_player_agent = agent2 if current_player_agent == agent1 else agent1\n",
        "\n",
        "# Mô phỏng 1000 ván đấu\n",
        "num_games = 1000\n",
        "wins_minimax = 0\n",
        "wins_random = 0\n",
        "draws = 0\n",
        "\n",
        "minimax_agent_4x4 = MinimaxAgent()\n",
        "# Định nghĩa lại agent để có signature phù hợp\n",
        "minimax_player = lambda board, player: minimax_agent_4x4.get_action(board, player)\n",
        "\n",
        "\n",
        "print(f\"Simulating {num_games} games on a 4x4 board...\")\n",
        "\n",
        "for i in range(num_games):\n",
        "    # Minimax đi trước\n",
        "    winner = play_game(minimax_player, random_player)\n",
        "    if winner == 1:\n",
        "        wins_minimax += 1\n",
        "    elif winner == -1:\n",
        "        wins_random += 1\n",
        "    else:\n",
        "        draws += 1\n",
        "\n",
        "    # Cho agent ngẫu nhiên đi trước\n",
        "    # (Để công bằng, ta nên cho mỗi agent đi trước 50% số ván)\n",
        "    # Tuy nhiên, Minimax vẫn sẽ thắng áp đảo\n",
        "    winner = play_game(random_player, minimax_player)\n",
        "    if winner == 1: # Random player thắng\n",
        "        wins_random += 1\n",
        "    elif winner == -1: # Minimax player thắng\n",
        "        wins_minimax += 1\n",
        "    else:\n",
        "        draws += 1\n",
        "\n",
        "print(\"\\n--- Simulation Results ---\")\n",
        "print(f\"Total games played: {num_games * 2}\")\n",
        "print(f\"Minimax Agent Wins: {wins_minimax} ({wins_minimax / (num_games * 2) * 100:.2f}%)\")\n",
        "print(f\"Random Agent Wins: {wins_random} ({wins_random / (num_games * 2) * 100:.2f}%)\")\n",
        "print(f\"Draws: {draws} ({draws / (num_games * 2) * 100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 4: Heuristic Alpha-Beta Tree Search\n",
        "###Heuristic evaluation function [15 points]\n",
        "Define and implement a heuristic evaluation function. Make sure that the heuristic value stays in the correct range."
      ],
      "metadata": {
        "id": "iqKA7qxVTEiF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RlRKLDa6GAfk"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "\n",
        "def heuristic(board, player):\n",
        "    \"\"\"\n",
        "    Heuristic evaluation function for Connect 4.\n",
        "    Scores based on potential winning lines (2, 3, and 4 pieces in a row).\n",
        "    Higher score is better for the 'player'.\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    opponent = -player\n",
        "    rows, cols = board.shape\n",
        "\n",
        "    # Helper to score a window of 4\n",
        "    def score_window(window):\n",
        "        s = 0\n",
        "        # Count player and opponent pieces, and empty spots in the window\n",
        "        player_pieces = window.count(player)\n",
        "        opponent_pieces = window.count(opponent)\n",
        "        empty_spots = window.count(0)\n",
        "\n",
        "        # Score based on potential lines\n",
        "        if player_pieces == 4:\n",
        "            s += 10000  # Winning line for the player\n",
        "        elif player_pieces == 3 and empty_spots == 1:\n",
        "            s += 100    # Potential winning line (3 in a row with one empty)\n",
        "        elif player_pieces == 2 and empty_spots == 2:\n",
        "            s += 10     # Potential line (2 in a row with two empty)\n",
        "\n",
        "        # Penalize opponent's potential winning lines\n",
        "        if opponent_pieces == 3 and empty_spots == 1:\n",
        "            s -= 1000   # Blocking opponent's potential win\n",
        "\n",
        "        return s\n",
        "\n",
        "    # Prioritize center column\n",
        "    center_col = cols // 2\n",
        "    center_array = [int(i) for i in list(board[:, center_col])]\n",
        "    score += center_array.count(player) * 5 # Slight bonus for occupying the center\n",
        "\n",
        "    # Score horizontal, vertical, and diagonal windows\n",
        "    # Horizontal\n",
        "    for r in range(rows):\n",
        "        row_array = [int(i) for i in list(board[r, :])]\n",
        "        for c in range(cols - 3):\n",
        "            window = row_array[c:c + 4]\n",
        "            score += score_window(window)\n",
        "\n",
        "    # Vertical\n",
        "    for c in range(cols):\n",
        "        col_array = [int(i) for i in list(board[:, c])]\n",
        "        for r in range(rows - 3):\n",
        "            window = col_array[r:r + 4]\n",
        "            score += score_window(window)\n",
        "\n",
        "    # Diagonal (top-left to bottom-right)\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols - 3):\n",
        "            window = [board[r + i][c + i] for i in range(4)]\n",
        "            score += score_window(window)\n",
        "\n",
        "    # Diagonal (bottom-left to top-right)\n",
        "    for r in range(3, rows):\n",
        "        for c in range(cols - 3):\n",
        "            window = [board[r - i][c + i] for i in range(4)]\n",
        "            score += score_window(window)\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjcJj50MGAfk"
      },
      "source": [
        "### Cutting Off Search [10 points]\n",
        "\n",
        "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MMTmzk2GAfk"
      },
      "outputs": [],
      "source": [
        "# Your code/ anwser goes here\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "# Reusing helper functions from previous tasks\n",
        "def actions(board):\n",
        "    return [c for c in range(board.shape[1]) if board[0, c] == 0]\n",
        "\n",
        "def result(board, player, action):\n",
        "    new_board = board.copy()\n",
        "    for row in reversed(range(board.shape[0])):\n",
        "        if new_board[row, action] == 0:\n",
        "            new_board[row, action] = player\n",
        "            return new_board\n",
        "    return new_board # Should not happen if actions is used correctly\n",
        "\n",
        "def check_winner(board):\n",
        "    rows, cols = board.shape\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if board[r,c] != 0:\n",
        "                p = board[r,c]\n",
        "                # Horizontal\n",
        "                if c+3 < cols and np.all(board[r,c:c+4] == p):\n",
        "                    return p\n",
        "                # Vertical\n",
        "                if r+3 < rows and np.all(board[r:r+4,c] == p):\n",
        "                    return p\n",
        "                # Diagonal /\n",
        "                if r+3 < rows and c+3 < cols and np.all([board[r+i][c+i] for i in range(4)] == p):\n",
        "                    return p\n",
        "                # Diagonal \\\n",
        "                if r+3 < rows and c-3 >= 0 and np.all([board[r+i][c-i] for i in range(4)] == p):\n",
        "                    return p\n",
        "    return 0\n",
        "\n",
        "def terminal(board):\n",
        "    return check_winner(board) != 0 or len(actions(board)) == 0\n",
        "\n",
        "def utility(board, player):\n",
        "    winner = check_winner(board)\n",
        "    if winner == player:\n",
        "        return 1\n",
        "    elif winner == -player:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0 # Draw or not terminal\n",
        "\n",
        "# Heuristic function (from the previous cell)\n",
        "def heuristic(board, player):\n",
        "    \"\"\"\n",
        "    Heuristic evaluation function for Connect 4.\n",
        "    Scores based on potential winning lines (2, 3, and 4 pieces in a row).\n",
        "    Higher score is better for the 'player'.\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    opponent = -player\n",
        "    rows, cols = board.shape\n",
        "\n",
        "    def score_window(window):\n",
        "        s = 0\n",
        "        player_pieces = window.count(player)\n",
        "        opponent_pieces = window.count(opponent)\n",
        "        empty_spots = window.count(0)\n",
        "\n",
        "        if player_pieces == 4:\n",
        "            s += 10000\n",
        "        elif player_pieces == 3 and empty_spots == 1:\n",
        "            s += 100\n",
        "        elif player_pieces == 2 and empty_spots == 2:\n",
        "            s += 10\n",
        "\n",
        "        if opponent_pieces == 3 and empty_spots == 1:\n",
        "            s -= 1000\n",
        "\n",
        "        return s\n",
        "\n",
        "    center_col = cols // 2\n",
        "    center_array = [int(i) for i in list(board[:, center_col])]\n",
        "    score += center_array.count(player) * 5\n",
        "\n",
        "    for r in range(rows):\n",
        "        row_array = [int(i) for i in list(board[r, :])]\n",
        "        for c in range(cols - 3):\n",
        "            window = row_array[c:c + 4]\n",
        "            score += score_window(window)\n",
        "\n",
        "    for c in range(cols):\n",
        "        col_array = [int(i) for i in list(board[:, c])]\n",
        "        for r in range(rows - 3):\n",
        "            window = col_array[r:r + 4]\n",
        "            score += score_window(window)\n",
        "\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols - 3):\n",
        "            window = [board[r + i][c + i] for i in range(4)]\n",
        "            score += score_window(window)\n",
        "\n",
        "    for r in range(3, rows):\n",
        "        for c in range(cols - 3):\n",
        "            window = [board[r - i][c + i] for i in range(4)]\n",
        "            score += score_window(window)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "# Heuristic Alpha-Beta Search with Cutoff\n",
        "class HeuristicAlphaBetaAgent:\n",
        "    def __init__(self, player=1, depth=4):\n",
        "        self.player = player\n",
        "        self.depth = depth\n",
        "        self.nodes_visited = 0 # Optional: for analysis\n",
        "\n",
        "    def get_action(self, board, player=1):\n",
        "        self.player = player\n",
        "        self.nodes_visited = 0\n",
        "        value, action = self.alphabeta(board, self.depth, -math.inf, math.inf, True)\n",
        "        return action\n",
        "\n",
        "    def alphabeta(self, board, depth, alpha, beta, maximizingPlayer):\n",
        "        self.nodes_visited += 1\n",
        "\n",
        "        # Base case: terminal state or depth cutoff\n",
        "        if terminal(board):\n",
        "            return utility(board, self.player) * 10000, None # Use utility directly for terminal states\n",
        "        if depth == 0:\n",
        "            return heuristic(board, self.player), None # Use heuristic at cutoff depth\n",
        "\n",
        "\n",
        "        valid_moves = actions(board)\n",
        "\n",
        "        if maximizingPlayer:\n",
        "            value = -math.inf\n",
        "            best_action = None\n",
        "            # Optional: Move ordering\n",
        "            # valid_moves = ordered_moves(valid_moves, board.shape[1]) # Need ordered_moves function\n",
        "\n",
        "            for action in valid_moves:\n",
        "                new_board = result(board, self.player, action)\n",
        "                v2, _ = self.alphabeta(new_board, depth - 1, alpha, beta, False)\n",
        "                if v2 > value:\n",
        "                    value = v2\n",
        "                    best_action = action\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break  # Beta cutoff\n",
        "            return value, best_action\n",
        "        else: # Minimizing player\n",
        "            value = math.inf\n",
        "            best_action = None\n",
        "            # Optional: Move ordering\n",
        "            # valid_moves = ordered_moves(valid_moves, board.shape[1]) # Need ordered_moves function\n",
        "\n",
        "            for action in valid_moves:\n",
        "                new_board = result(board, -self.player, action)\n",
        "                v2, _ = self.alphabeta(new_board, depth - 1, alpha, beta, True)\n",
        "                if v2 < value:\n",
        "                    value = v2\n",
        "                    best_action = action\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break  # Alpha cutoff\n",
        "            return value, best_action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75URIXZEGAfl"
      },
      "source": [
        "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYv-DdPzGAfl"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Reuse helper functions and HeuristicAlphaBetaAgent from previous cells\n",
        "\n",
        "# Manual test boards (from Task 3)\n",
        "board1 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [1, 1, 1, 0]\n",
        "]) # Win horizontally\n",
        "\n",
        "board2 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0,-1, 0, 0],\n",
        "    [0,-1, 1, 0],\n",
        "    [1,-1, 1, 0]\n",
        "]) # Block vertically\n",
        "\n",
        "board3 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0,-1],\n",
        "    [0, 1,-1, 0],\n",
        "    [1,-1, 1, 1]\n",
        "]) # Block diagonally\n",
        "\n",
        "board4 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [0,-1, 0, 0],\n",
        "    [1, 1,-1, 0]\n",
        "]) # Setup a fork\n",
        "\n",
        "board5 = np.array([\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [-1,-1, 1, 0],\n",
        "    [1, 1,-1,-1]\n",
        "]) # Complex middle game\n",
        "\n",
        "test_boards = {\n",
        "    \"Board 1 (Win Horizontally)\": board1,\n",
        "    \"Board 2 (Block Vertically)\": board2,\n",
        "    \"Board 3 (Block Diagonally)\": board3,\n",
        "    \"Board 4 (Setup a fork)\": board4,\n",
        "    \"Board 5 (Complex middle game)\": board5\n",
        "}\n",
        "\n",
        "# Test with different cutoff depths\n",
        "cutoff_depths = [2, 4, 6] # Experiment with different depths\n",
        "\n",
        "for name, board in test_boards.items():\n",
        "    print(f\"--- Testing {name} ---\")\n",
        "    print(\"Board state:\")\n",
        "    print(board)\n",
        "\n",
        "    for depth in cutoff_depths:\n",
        "        agent = HeuristicAlphaBetaAgent(depth=depth)\n",
        "        # Player 1's turn\n",
        "        best_move = agent.get_action(board, player=1)\n",
        "\n",
        "        print(f\"Agent (Depth={depth}, Player 1) chose column: {best_move}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtlBDeGzGAfl"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB0YmPVsGAfl"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reuse helper functions and HeuristicAlphaBetaAgent from previous cells\n",
        "\n",
        "board_sizes = [\n",
        "    (4, 4),\n",
        "    (4, 5),\n",
        "    (5, 5),\n",
        "    (5, 6),\n",
        "    (6, 7) # Standard board\n",
        "]\n",
        "\n",
        "cutoff_depths = [2, 4, 6] # Experiment with different depths\n",
        "\n",
        "timing_results = {}\n",
        "\n",
        "for rows, cols in board_sizes:\n",
        "    board = np.zeros((rows, cols), dtype=int)\n",
        "    print(f\"Calculating first move for a {rows}x{cols} board with different depths...\")\n",
        "\n",
        "    for depth in cutoff_depths:\n",
        "        agent = HeuristicAlphaBetaAgent(depth=depth)\n",
        "\n",
        "        start_time = time.time()\n",
        "        agent.get_action(board, player=1)\n",
        "        end_time = time.time()\n",
        "\n",
        "        duration = end_time - start_time\n",
        "        key = f\"{rows}x{cols}_Depth{depth}\"\n",
        "        timing_results[key] = duration\n",
        "        print(f\"Board {rows}x{cols}, Depth {depth}: {duration:.4f} seconds\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "\n",
        "print(\"\\n--- Timing Results Summary ---\")\n",
        "# Convert results to a DataFrame for better display\n",
        "data = []\n",
        "for key, value in timing_results.items():\n",
        "    board_size, depth_str = key.split(\"_\")\n",
        "    rows, cols = map(int, board_size.split('x'))\n",
        "    depth = int(depth_str.replace(\"Depth\", \"\"))\n",
        "    data.append({'Rows': rows, 'Cols': cols, 'Depth': depth, 'Time (s)': value})\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df_pivot = df.pivot_table(index=['Rows', 'Cols'], columns='Depth', values='Time (s)')\n",
        "print(df_pivot)\n",
        "\n",
        "print(\"\\nAnalysis:\")\n",
        "print(\"As the board size and cutoff depth increase, the time taken to make a move increases significantly.\")\n",
        "print(\"This is expected because the search space (number of nodes visited) grows exponentially with both factors.\")\n",
        "print(\"For the standard 6x7 board, even with a cutoff depth of 6, the time taken can be substantial, though much faster than pure Minimax.\")\n",
        "print(\"Choosing an appropriate cutoff depth is a trade-off between decision quality and computational efficiency.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL9WiSl7GAfq"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_HjBh6HGAfq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "# --- Reuse the Connect4Game class from Task 3 ---\n",
        "class Connect4Game:\n",
        "    def __init__(self, rows=6, cols=7):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.board = np.zeros((rows, cols), dtype=int)\n",
        "\n",
        "    def copy(self):\n",
        "        new_game = Connect4Game(self.rows, self.cols)\n",
        "        new_game.board = np.copy(self.board)\n",
        "        return new_game\n",
        "\n",
        "    def available_actions(self):\n",
        "        return [c for c in range(self.cols) if self.board[0][c] == 0]\n",
        "\n",
        "    def make_move(self, col, player):\n",
        "        for r in range(self.rows - 1, -1, -1):\n",
        "            if self.board[r][col] == 0:\n",
        "                self.board[r][col] = player\n",
        "                break\n",
        "\n",
        "    def is_full(self):\n",
        "        return np.all(self.board != 0)\n",
        "\n",
        "    def check_winner(self):\n",
        "        b = self.board\n",
        "        # Rows\n",
        "        for r in range(self.rows):\n",
        "            for c in range(self.cols - 3):\n",
        "                if abs(sum(b[r, c:c + 4])) == 4:\n",
        "                    return np.sign(sum(b[r, c:c + 4]))\n",
        "        # Columns\n",
        "        for c in range(self.cols):\n",
        "            for r in range(self.rows - 3):\n",
        "                if abs(sum(b[r:r + 4, c])) == 4:\n",
        "                    return np.sign(sum(b[r:r + 4, c]))\n",
        "        # Diagonals /\n",
        "        for r in range(self.rows - 3):\n",
        "            for c in range(self.cols - 3):\n",
        "                if abs(sum([b[r + i][c + i] for i in range(4)])) == 4:\n",
        "                    return np.sign(sum([b[r + i][c + i] for i in range(4)]))\n",
        "        # Diagonals \\\n",
        "        for r in range(3, self.rows):\n",
        "            for c in range(self.cols - 3):\n",
        "                if abs(sum([b[r - i][c + i] for i in range(4)])) == 4:\n",
        "                    return np.sign(sum([b[r - i][c + i] for i in range(4)]))\n",
        "        return 0\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return self.check_winner() != 0 or self.is_full()\n",
        "\n",
        "\n",
        "# --- Move ordering ---\n",
        "def ordered_moves(moves, cols):\n",
        "    center = cols // 2\n",
        "    return sorted(moves, key=lambda x: abs(center - x))\n",
        "\n",
        "\n",
        "# --- Heuristic Alpha-Beta Agent ---\n",
        "class HeuristicAlphaBetaAgent:\n",
        "    def __init__(self, player=1, depth=4):\n",
        "        self.player = player\n",
        "        self.depth = depth\n",
        "\n",
        "    def evaluate(self, game):\n",
        "        \"\"\"Heuristic: điểm số dựa trên số chuỗi 2, 3, 4 của người chơi.\"\"\"\n",
        "        board = game.board\n",
        "        score = 0\n",
        "        player = self.player\n",
        "        opponent = -player\n",
        "\n",
        "        def window_score(window):\n",
        "            s = 0\n",
        "            if window.count(player) == 4:\n",
        "                s += 1000\n",
        "            elif window.count(player) == 3 and window.count(0) == 1:\n",
        "                s += 5\n",
        "            elif window.count(player) == 2 and window.count(0) == 2:\n",
        "                s += 2\n",
        "            if window.count(opponent) == 3 and window.count(0) == 1:\n",
        "                s -= 4\n",
        "            return s\n",
        "\n",
        "        # Trung tâm\n",
        "        center_array = [int(i) for i in list(board[:, game.cols // 2])]\n",
        "        score += center_array.count(player) * 3\n",
        "\n",
        "        # Hàng ngang\n",
        "        for r in range(game.rows):\n",
        "            row_array = [int(i) for i in list(board[r, :])]\n",
        "            for c in range(game.cols - 3):\n",
        "                window = row_array[c:c + 4]\n",
        "                score += window_score(window)\n",
        "        # Cột dọc\n",
        "        for c in range(game.cols):\n",
        "            col_array = [int(i) for i in list(board[:, c])]\n",
        "            for r in range(game.rows - 3):\n",
        "                window = col_array[r:r + 4]\n",
        "                score += window_score(window)\n",
        "        # Chéo /\n",
        "        for r in range(game.rows - 3):\n",
        "            for c in range(game.cols - 3):\n",
        "                window = [board[r + i][c + i] for i in range(4)]\n",
        "                score += window_score(window)\n",
        "        # Chéo \\\n",
        "        for r in range(3, game.rows):\n",
        "            for c in range(game.cols - 3):\n",
        "                window = [board[r - i][c + i] for i in range(4)]\n",
        "                score += window_score(window)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def minimax(self, game, depth, alpha, beta, maximizing):\n",
        "        if depth == 0 or game.is_terminal():\n",
        "            return self.evaluate(game)\n",
        "\n",
        "        valid_moves = ordered_moves(game.available_actions(), game.cols)\n",
        "\n",
        "        if maximizing:\n",
        "            value = -math.inf\n",
        "            for col in valid_moves:\n",
        "                new_game = game.copy()\n",
        "                new_game.make_move(col, self.player)\n",
        "                value = max(value, self.minimax(new_game, depth - 1, alpha, beta, False))\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "        else:\n",
        "            value = math.inf\n",
        "            for col in valid_moves:\n",
        "                new_game = game.copy()\n",
        "                new_game.make_move(col, -self.player)\n",
        "                value = min(value, self.minimax(new_game, depth - 1, alpha, beta, True))\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "    def get_action(self, game):\n",
        "        valid_moves = ordered_moves(game.available_actions(), game.cols)\n",
        "        best_score = -math.inf\n",
        "        best_move = np.random.choice(valid_moves)\n",
        "        for col in valid_moves:\n",
        "            new_game = game.copy()\n",
        "            new_game.make_move(col, self.player)\n",
        "            score = self.minimax(new_game, self.depth - 1, -math.inf, math.inf, False)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_move = col\n",
        "        return best_move\n",
        "\n",
        "# --- Reuse visualize function from Task 2 ---\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize(board):\n",
        "    plt.axes()\n",
        "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
        "    circles=[]\n",
        "    for i,row in enumerate(board):\n",
        "        for j,val in enumerate(row):\n",
        "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
        "            circles.append(plt.Circle((j,i*-1),0.4,fc=color)) # Corrected y-coordinate calculation\n",
        "\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    for circle in circles:\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Simulate a game between two heuristic alpha-beta agents\n",
        "game = Connect4Game(rows=6, cols=7)\n",
        "agent1 = HeuristicAlphaBetaAgent(player=1, depth=3) # Red player\n",
        "agent2 = HeuristicAlphaBetaAgent(player=-1, depth=5) # Yellow player\n",
        "\n",
        "turn = 1\n",
        "move_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"Starting game between Agent 1 (Depth=3, Red) and Agent 2 (Depth=5, Yellow)\")\n",
        "visualize(game.board) # Visualize initial empty board\n",
        "\n",
        "while not game.is_terminal():\n",
        "    current_player_agent = agent1 if turn == 1 else agent2\n",
        "    player_name = \"Red (Agent 1)\" if turn == 1 else \"Yellow (Agent 2)\"\n",
        "    agent_depth = agent1.depth if turn == 1 else agent2.depth\n",
        "\n",
        "    print(f\"\\n--- Move {move_count + 1} ---\")\n",
        "    print(f\"{player_name}'s turn (Depth={agent_depth})\")\n",
        "\n",
        "    col = current_player_agent.get_action(game)\n",
        "\n",
        "    print(f\"{player_name} chooses column: {col}\")\n",
        "    game.make_move(col, turn)\n",
        "    visualize(game.board) # Visualize board after the move\n",
        "\n",
        "    move_count += 1\n",
        "    winner = game.check_winner()\n",
        "    if winner != 0:\n",
        "        break\n",
        "\n",
        "    turn *= -1  # switch turn\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"\\n--- Game Over ---\")\n",
        "print(\"Final Board:\")\n",
        "print(game.board)\n",
        "if winner == 1:\n",
        "    print(\"\\n Agent 1 (Depth=3, Red) wins!\")\n",
        "elif winner == -1:\n",
        "    print(\"\\n Agent 2 (Depth=5, Yellow) wins!\")\n",
        "else:\n",
        "    print(\"\\n It's a draw!\")\n",
        "\n",
        "print(f\"Total Moves: {move_count}\")\n",
        "print(f\"Total Play Time: {round(end_time - start_time, 2)} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekMdHEnfGAfq"
      },
      "source": [
        "## Challenge task [up to +10 bonus point will be awarded separately]\n",
        "\n",
        "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_jkNDOyGAfr"
      },
      "source": [
        "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
        "\n",
        "### Pure Monte Carlo Search\n",
        "\n",
        "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ddYIYC8GAfr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def simulate_random_game(board, player):\n",
        "    temp_board = board.copy()\n",
        "    current_player = player\n",
        "\n",
        "    while not terminal(temp_board):\n",
        "        move = random.choice(actions(temp_board))\n",
        "        temp_board = result(temp_board, current_player, move)\n",
        "        current_player *= -1\n",
        "\n",
        "    return utility(temp_board, player)\n",
        "\n",
        "def monte_carlo_player(board, player=1, simulations=50):\n",
        "    best_move = None\n",
        "    best_score = -999999\n",
        "\n",
        "    for move in actions(board):\n",
        "        win_score = 0\n",
        "        for _ in range(simulations):\n",
        "            result_board = result(board, player, move)\n",
        "            win_score += simulate_random_game(result_board, -player)\n",
        "        if win_score > best_score:\n",
        "            best_score = win_score\n",
        "            best_move = move\n",
        "\n",
        "    return best_move\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwq7bIMlGAfr"
      },
      "source": [
        "### Best First Move\n",
        "\n",
        "Use your Monte Carlo Search to determine what the best first move for red is? Describe under what assumptions this is the \"best\" first move.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gK-LpxrmGAfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e976d3-be8f-4ffe-ee89-c61e83a89cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tìm nước đi đầu tiên tốt nhất cho bàn cờ 6x7 bằng Pure Monte Carlo Search...\n",
            "Monte Carlo scores: {0: '51.10%', 1: '52.25%', 2: '58.70%', 3: '65.20%', 4: '56.05%', 5: '55.95%', 6: '51.95%'}\n",
            "--------------------------------------------------\n",
            "Quá trình tính toán mất: 17.76 giây.\n",
            "Số mô phỏng cho mỗi nước đi: 1000\n",
            "==> Nước đi đầu tiên tốt nhất được tìm thấy là cột: 3\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "def empty_board(rows=6, cols=7):\n",
        "    return np.zeros((rows, cols), dtype=int)\n",
        "\n",
        "def actions(board):\n",
        "    return [c for c in range(board.shape[1]) if board[0, c] == 0]\n",
        "\n",
        "def result(board, player, action):\n",
        "    b = board.copy()\n",
        "    rows = b.shape[0]\n",
        "    # Tìm hàng thấp nhất còn trống trong cột đã chọn\n",
        "    for r in range(rows - 1, -1, -1):\n",
        "        if b[r, action] == 0:\n",
        "            b[r, action] = player\n",
        "            return b\n",
        "    # Nếu không tìm thấy ô trống (lỗi logic), trả về lỗi\n",
        "    raise ValueError(f\"Hành động không hợp lệ: Cột {action} đã đầy.\")\n",
        "\n",
        "def check_winner(board, k=4):\n",
        "    rows, cols = board.shape\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            player = board[r, c]\n",
        "            if player == 0:\n",
        "                continue\n",
        "\n",
        "            # Kiểm tra hàng ngang sang phải\n",
        "            if c + k <= cols and np.all(board[r, c:c+k] == player):\n",
        "                return player\n",
        "            # Kiểm tra hàng dọc xuống dưới\n",
        "            if r + k <= rows and np.all(board[r:r+k, c] == player):\n",
        "                return player\n",
        "            # Kiểm tra đường chéo chính (từ trên-trái xuống dưới-phải)\n",
        "            if r + k <= rows and c + k <= cols and np.all([board[r+i, c+i] for i in range(k)] == player):\n",
        "                return player\n",
        "            # Kiểm tra đường chéo phụ (từ dưới-trái lên trên-phải)\n",
        "            if r - k + 1 >= 0 and c + k <= cols and np.all([board[r-i, c+i] for i in range(k)] == player):\n",
        "                return player\n",
        "\n",
        "    return 0\n",
        "\n",
        "def terminal(board, k=4):\n",
        "    winner = check_winner(board, k)\n",
        "    if winner != 0:\n",
        "        return True, winner\n",
        "    if not actions(board):\n",
        "        return True, 0\n",
        "\n",
        "    return False, 0\n",
        "\n",
        "class MonteCarloAgent:\n",
        "    def __init__(self, num_simulations=100):\n",
        "        self.num_simulations = num_simulations\n",
        "\n",
        "    def __call__(self, board, player=1):\n",
        "        possible_actions = actions(board)\n",
        "        if not possible_actions:\n",
        "            return None\n",
        "        if len(possible_actions) == 1:\n",
        "            return possible_actions[0]\n",
        "\n",
        "        action_scores = {}\n",
        "\n",
        "        for action in possible_actions:\n",
        "            wins = 0\n",
        "            for _ in range(self.num_simulations):\n",
        "                next_board = result(board, player, action)\n",
        "\n",
        "                winner = self.simulate_playout(next_board, -player)\n",
        "\n",
        "                if winner == player:\n",
        "                    wins += 1\n",
        "                elif winner == 0:\n",
        "                    wins += 0.5\n",
        "\n",
        "            action_scores[action] = wins / self.num_simulations\n",
        "\n",
        "        print(f\"Monte Carlo scores: { {k: f'{v:.2%}' for k, v in sorted(action_scores.items())} }\")\n",
        "\n",
        "        best_action = max(action_scores, key=action_scores.get)\n",
        "        return best_action\n",
        "\n",
        "    def simulate_playout(self, board, starting_player):\n",
        "        current_board = board.copy()\n",
        "        current_player = starting_player\n",
        "\n",
        "        while True:\n",
        "            is_terminal, winner = terminal(current_board)\n",
        "            if is_terminal:\n",
        "                return winner\n",
        "\n",
        "            possible_moves = actions(current_board)\n",
        "            move = random.choice(possible_moves)\n",
        "\n",
        "            current_board = result(current_board, current_player, move)\n",
        "\n",
        "            current_player = -current_player\n",
        "\n",
        "print(\"Đang tìm nước đi đầu tiên tốt nhất cho bàn cờ 6x7 bằng Pure Monte Carlo Search...\")\n",
        "\n",
        "num_sims_per_action = 1000\n",
        "mc_agent_for_first_move = MonteCarloAgent(num_simulations=num_sims_per_action)\n",
        "\n",
        "initial_board = empty_board(rows=6, cols=7)\n",
        "\n",
        "start_time = time.time()\n",
        "best_first_move = mc_agent_for_first_move(initial_board, player=1)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"Quá trình tính toán mất: {end_time - start_time:.2f} giây.\")\n",
        "print(f\"Số mô phỏng cho mỗi nước đi: {num_sims_per_action}\")\n",
        "print(f\"==> Nước đi đầu tiên tốt nhất được tìm thấy là cột: {best_first_move}\")\n",
        "print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}